{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "#################################################\n",
    "import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "# import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"# cpus: \", os.cpu_count())\n",
    "NUM_PROCESSES = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [00:47<00:00, 1327.24it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 501577.68it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 571085.26it/s]\n",
      "100%|██████████| 63325/63325 [00:57<00:00, 1102.41it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 1809.09it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 2009.20it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./train.txt\") as f:\n",
    "    train_file_list = f.readlines()\n",
    "with open(\"./val.txt\") as f:\n",
    "    val_file_list = f.readlines()\n",
    "with open(\"./test.txt\") as f:\n",
    "    test_file_list = f.readlines()\n",
    "\n",
    "train_file_list = [x.strip().split(sep=\" \") for x in train_file_list]\n",
    "val_file_list = [x.strip().split(sep=\" \") for x in val_file_list]\n",
    "test_file_list = [x.strip().split(sep=\" \") for x in test_file_list]\n",
    "\n",
    "train_label = [int(x[1]) for x in train_file_list]\n",
    "val_label = [int(x[1]) for x in val_file_list]\n",
    "test_label = [int(x[1]) for x in test_file_list]\n",
    "\n",
    "train_file_list = [x[0] for x in train_file_list]\n",
    "val_file_list = [x[0] for x in val_file_list]\n",
    "test_file_list = [x[0] for x in test_file_list]\n",
    "\n",
    "# print(\"# cpus: \", os.cpu_count())\n",
    "NUM_PROCESSES = 8\n",
    "\n",
    "def ReadImage(filePath):\n",
    "    image = cv2.imread(filePath, cv2.IMREAD_COLOR)\n",
    "    # image = cv2.imread(filePath, cv2.IMREAD_GRAYSCALE)\n",
    "    # image = cv2.resize(image, (256, 256))\n",
    "    return image\n",
    "\n",
    "with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "    train_imgs = pool.map(ReadImage, tqdm(train_file_list))\n",
    "    val_imgs = pool.map(ReadImage, tqdm(val_file_list))\n",
    "    test_imgs = pool.map(ReadImage, tqdm(test_file_list))\n",
    "\n",
    "# resize the images to 256x256\n",
    "def ResizeImage(image):\n",
    "    # resized_img = cv2.resize(image, (256, 256))\n",
    "    resized_img = cv2.resize(image, (32, 32))\n",
    "    return resized_img\n",
    "\n",
    "with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "    resized_train_imgs = pool.map(ResizeImage, tqdm(train_imgs))\n",
    "    resized_val_imgs = pool.map(ResizeImage, tqdm(val_imgs))\n",
    "    resized_test_imgs = pool.map(ResizeImage, tqdm(test_imgs))\n",
    "\n",
    "##########################################################################################################\n",
    "# def FlattenImages(image: np.ndarray) -> np.ndarray:\n",
    "#     return image.flatten()\n",
    "\n",
    "# with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "#     flatten_resized_train_imgs = np.array(pool.map(FlattenImages, tqdm(resized_train_imgs)))\n",
    "#     flatten_resized_val_imgs = np.array(pool.map(FlattenImages, tqdm(resized_val_imgs)))\n",
    "#     flatten_resized_test_imgs = np.array(pool.map(FlattenImages, tqdm(resized_test_imgs)))\n",
    "\n",
    "\n",
    "# # Ref.: https://github.com/Ixiaohuihuihui/Extract-color-histogram-feature/blob/master/rgb_feature.py\n",
    "# # extract rgb features\n",
    "# def ExtractColorHistFeatures(image):\n",
    "#     features = []\n",
    "#     for channel in range(3):\n",
    "#         hist = cv2.calcHist(images=[image], channels=[channel], mask=None, histSize=[64], ranges=[0,256])\n",
    "#         hist = cv2.normalize(hist, hist)\n",
    "#         # features.extend(hist)\n",
    "#         features.append(hist)\n",
    "#     return features\n",
    "\n",
    "# with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "#     ### tqdm returns an iterator\n",
    "#     # train_features = pool.map(ExtractFeatures, tqdm(resized_train_imgs))\n",
    "#     # val_features = pool.map(ExtractFeatures, tqdm(resized_val_imgs))\n",
    "#     # test_features = pool.map(ExtractFeatures, tqdm(resized_test_imgs))\n",
    "#     train_features = list(tqdm(pool.imap(ExtractColorHistFeatures, resized_train_imgs), total=len(resized_train_imgs)))\n",
    "#     val_features = list(tqdm(pool.imap(ExtractColorHistFeatures, resized_val_imgs), total=len(resized_val_imgs)))\n",
    "#     test_features = list(tqdm(pool.imap(ExtractColorHistFeatures, resized_test_imgs), total=len(resized_test_imgs)))\n",
    "\n",
    "\n",
    "# # flatten and reshape the features into (n_samples, n_features)\n",
    "# train_features = np.array(train_features)\n",
    "# val_features = np.array(val_features)\n",
    "# test_features = np.array(test_features)\n",
    "\n",
    "# def FlattenFeatures(feature):\n",
    "#     return feature.flatten()\n",
    "\n",
    "# with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "#     train_features = np.array(pool.map(FlattenFeatures, tqdm(train_features)))\n",
    "#     val_features = np.array(pool.map(FlattenFeatures, tqdm(val_features)))\n",
    "#     test_features = np.array(pool.map(FlattenFeatures, tqdm(test_features)))\n",
    "\n",
    "# # flatten and reshape the features into (n_samples, n_features)\n",
    "# resized_train_imgs = np.array(resized_train_imgs)\n",
    "# resized_val_imgs = np.array(resized_val_imgs)\n",
    "# resized_test_imgs = np.array(resized_test_imgs)\n",
    "\n",
    "# def FlattenImages(image):\n",
    "#     return image.flatten()\n",
    "\n",
    "# with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "#     resized_train_imgs = np.array(pool.map(FlattenImages, tqdm(resized_train_imgs)))\n",
    "#     resized_val_imgs = np.array(pool.map(FlattenImages, tqdm(resized_val_imgs)))\n",
    "#     resized_test_imgs = np.array(pool.map(FlattenImages, tqdm(resized_test_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=\"./data/resized_train_imgs.npy\", arr=resized_train_imgs)\n",
    "np.save(file=\"./data/resized_val_imgs.npy\", arr=resized_val_imgs)\n",
    "np.save(file=\"./data/resized_test_imgs.npy\", arr=resized_test_imgs)\n",
    "np.save(file=\"./data/train_label\", arr=train_label)\n",
    "np.save(file=\"./data/val_label\", arr=val_label)\n",
    "np.save(file=\"./data/test_label\", arr=test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_train_imgs = np.load(file=\"./data/resized_train_imgs.npy\")\n",
    "resized_val_imgs = np.load(file=\"./data/resized_val_imgs.npy\")\n",
    "resized_test_imgs = np.load(file=\"./data/resized_test_imgs.npy\")\n",
    "train_label = np.load(file=\"./data/train_label.npy\")\n",
    "val_label = np.load(file=\"./data/val_label.npy\")\n",
    "test_label = np.load(file=\"./data/test_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [00:01<00:00, 57181.18it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 44417.59it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 50715.74it/s]\n"
     ]
    }
   ],
   "source": [
    "def MoveColorChannel(image: np.ndarray) -> np.ndarray:\n",
    "    return np.moveaxis(image, source=2, destination=0)  # reshape (H, W, C) to (C, H, W)\n",
    "\n",
    "with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "    resized_train_imgs = pool.map(MoveColorChannel, tqdm(resized_train_imgs))\n",
    "    resized_val_imgs = pool.map(MoveColorChannel, tqdm(resized_val_imgs))\n",
    "    resized_test_imgs = pool.map(MoveColorChannel, tqdm(resized_test_imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shuffle\n",
    "# def shuffle(imgs: list, label: list) -> list:\n",
    "#     random.seed(42)\n",
    "#     idx = np.arange(len(imgs))\n",
    "#     random.shuffle(idx)\n",
    "#     imgs = [imgs[i] for i in idx]\n",
    "#     label = [label[i] for i in idx]\n",
    "#     return imgs, label\n",
    "\n",
    "# resized_train_imgs, train_label = shuffle(resized_train_imgs, train_label)\n",
    "# resized_val_imgs, val_label = shuffle(resized_val_imgs, val_label)\n",
    "# resized_test_imgs, test_label = shuffle(resized_test_imgs, test_label)\n",
    "\n",
    "# convert list to numpy.ndarray\n",
    "resized_train_imgs = np.array(resized_train_imgs)\n",
    "resized_val_imgs = np.array(resized_val_imgs)\n",
    "resized_test_imgs = np.array(resized_test_imgs)\n",
    "# list to numpy.ndarray\n",
    "train_label = np.array(train_label)\n",
    "val_label = np.array(val_label)\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63325, 3, 32, 32)\n",
      "(450, 3, 32, 32)\n",
      "(450, 3, 32, 32)\n",
      "\n",
      "(63325,)\n",
      "(450,)\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "# check the shape\n",
    "print(resized_train_imgs.shape)\n",
    "print(resized_val_imgs.shape)\n",
    "print(resized_test_imgs.shape)\n",
    "print()\n",
    "print(train_label.shape)\n",
    "print(val_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = [\n",
    "# \t[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
    "# \t[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
    "# \t[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
    "# \t[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
    "# ]\n",
    "\n",
    "# def download_mnist():\n",
    "#     base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "#     for name in filename:\n",
    "#         print(\"Downloading \"+name[1]+\"...\")\n",
    "#         request.urlretrieve(base_url+name[1], name[1])\n",
    "#     print(\"Download complete.\")\n",
    "\n",
    "# def save_mnist():\n",
    "#     mnist = {}\n",
    "#     for name in filename[:2]:\n",
    "#         with gzip.open(name[1], 'rb') as f:\n",
    "#             mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
    "#     for name in filename[-2:]:\n",
    "#         with gzip.open(name[1], 'rb') as f:\n",
    "#             mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "#     with open(\"mnist.pkl\", 'wb') as f:\n",
    "#         pickle.dump(mnist,f)\n",
    "#     print(\"Save complete.\")\n",
    "\n",
    "# def init():\n",
    "#     download_mnist()\n",
    "#     save_mnist()\n",
    "\n",
    "# def load():\n",
    "#     with open(\"./lenet-5-mnist-from-scratch-numpy/mnist.pkl\",'rb') as f:\n",
    "#         mnist = pickle.load(f)\n",
    "#     return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeOneHot(Y, D_out):\n",
    "    N = Y.shape[0]\n",
    "    Z = np.zeros((N, D_out))\n",
    "    Z[np.arange(N), Y] = 1\n",
    "    return Z\n",
    "\n",
    "def draw_losses(losses):\n",
    "    t = np.arange(len(losses))\n",
    "    plt.plot(t, losses)\n",
    "    plt.show()\n",
    "\n",
    "def get_batch(X, Y, batch_size):\n",
    "    N = len(X)\n",
    "    i = random.randint(1, N-batch_size)\n",
    "    return X[i:i+batch_size], Y[i:i+batch_size]\n",
    "\n",
    "class FC():\n",
    "    \"\"\"\n",
    "    Fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self, D_in, D_out):\n",
    "        #print(\"Build FC\")\n",
    "        self.cache = None\n",
    "        #self.W = {'val': np.random.randn(D_in, D_out), 'grad': 0}\n",
    "        self.W = {'val': np.random.normal(0.0, np.sqrt(2/D_in), (D_in,D_out)), 'grad': 0}\n",
    "        self.b = {'val': np.random.randn(D_out), 'grad': 0}\n",
    "\n",
    "    def _forward(self, X):\n",
    "        #print(\"FC: _forward\")\n",
    "        out = np.dot(X, self.W['val']) + self.b['val']\n",
    "        self.cache = X\n",
    "        return out\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        #print(\"FC: _backward\")\n",
    "        X = self.cache\n",
    "        dX = np.dot(dout, self.W['val'].T).reshape(X.shape)\n",
    "        self.W['grad'] = np.dot(X.reshape(X.shape[0], np.prod(X.shape[1:])).T, dout)\n",
    "        self.b['grad'] = np.sum(dout, axis=0)\n",
    "        #self._update_params()\n",
    "        return dX\n",
    "\n",
    "    def _update_params(self, lr=0.001):\n",
    "        # Update the parameters\n",
    "        self.W['val'] -= lr*self.W['grad']\n",
    "        self.b['val'] -= lr*self.b['grad']\n",
    "\n",
    "class ReLU():\n",
    "    \"\"\"\n",
    "    ReLU activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        #print(\"Build ReLU\")\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        #print(\"ReLU: _forward\")\n",
    "        out = np.maximum(0, X)\n",
    "        self.cache = X\n",
    "        return out\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        #print(\"ReLU: _backward\")\n",
    "        X = self.cache\n",
    "        dX = np.array(dout, copy=True)\n",
    "        dX[X <= 0] = 0\n",
    "        return dX\n",
    "\n",
    "class Sigmoid():\n",
    "    \"\"\"\n",
    "    Sigmoid activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        self.cache = X\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X = self.cache\n",
    "        X = self._forward(X)  # 與原作者不同，新增這行\n",
    "        dX = dout*X*(1-X)\n",
    "        return dX\n",
    "\n",
    "class tanh():\n",
    "    \"\"\"\n",
    "    tanh activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.cache = X\n",
    "\n",
    "    def _forward(self, X):\n",
    "        self.cache = X\n",
    "        return np.tanh(X)\n",
    "\n",
    "    def _backward(self, X):\n",
    "        X = self.cache\n",
    "        dX = dout*(1 - np.tanh(X)**2)\n",
    "        return dX\n",
    "\n",
    "class Softmax():\n",
    "    \"\"\"\n",
    "    Softmax activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        #print(\"Build Softmax\")\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        #print(\"Softmax: _forward\")\n",
    "        maxes = np.amax(X, axis=1)\n",
    "        maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "        Y = np.exp(X - maxes)\n",
    "        Z = Y / np.sum(Y, axis=1).reshape(Y.shape[0], 1)\n",
    "        self.cache = (X, Y, Z)\n",
    "        return Z # distribution\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X, Y, Z = self.cache\n",
    "        dZ = np.zeros(X.shape)\n",
    "        dY = np.zeros(X.shape)\n",
    "        dX = np.zeros(X.shape)\n",
    "        N = X.shape[0]\n",
    "        for n in range(N):\n",
    "            i = np.argmax(Z[n])\n",
    "            dZ[n,:] = np.diag(Z[n]) - np.outer(Z[n],Z[n])\n",
    "            M = np.zeros((N,N))\n",
    "            M[:,i] = 1\n",
    "            dY[n,:] = np.eye(N) - M\n",
    "        dX = np.dot(dout,dZ)\n",
    "        dX = np.dot(dX,dY)\n",
    "        return dX\n",
    "\n",
    "\n",
    "class Dropout():\n",
    "    \"\"\"\n",
    "    Dropout layer\n",
    "    \"\"\"\n",
    "    def __init__(self, p=1):\n",
    "        self.cache = None\n",
    "        self.p = p\n",
    "\n",
    "    def _forward(self, X):\n",
    "        M = (np.random.rand(*X.shape) < self.p) / self.p\n",
    "        self.cache = X, M\n",
    "        return X*M\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X, M = self.cache\n",
    "        dX = dout*M/self.p\n",
    "        return dX\n",
    "\n",
    "class Conv():\n",
    "    \"\"\"\n",
    "    Conv layer\n",
    "    \"\"\"\n",
    "    def __init__(self, Cin, Cout, F, stride=1, padding=0, bias=True):\n",
    "        self.Cin = Cin\n",
    "        self.Cout = Cout\n",
    "        self.F = F\n",
    "        self.S = stride\n",
    "        #self.W = {'val': np.random.randn(Cout, Cin, F, F), 'grad': 0}\n",
    "        self.W = {'val': np.random.normal(0.0,np.sqrt(2/Cin),(Cout,Cin,F,F)), 'grad': 0} # Xavier Initialization\n",
    "        self.b = {'val': np.random.randn(Cout), 'grad': 0}\n",
    "        self.cache = None\n",
    "        self.pad = padding\n",
    "\n",
    "    def _forward(self, X):\n",
    "        X = np.pad(X, ((0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)), 'constant')\n",
    "        (N, Cin, H, W) = X.shape\n",
    "        H_ = H - self.F + 1\n",
    "        W_ = W - self.F + 1\n",
    "        Y = np.zeros((N, self.Cout, H_, W_))\n",
    "\n",
    "        for n in range(N):\n",
    "            for c in range(self.Cout):\n",
    "                for h in range(H_):\n",
    "                    for w in range(W_):\n",
    "                        Y[n, c, h, w] = np.sum(X[n, :, h:h+self.F, w:w+self.F] * self.W['val'][c, :, :, :]) + self.b['val'][c]\n",
    "\n",
    "        self.cache = X\n",
    "        return Y\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        # dout (N,Cout,H_,W_)\n",
    "        # W (Cout, Cin, F, F)\n",
    "        X = self.cache\n",
    "        (N, Cin, H, W) = X.shape\n",
    "        H_ = H - self.F + 1\n",
    "        W_ = W - self.F + 1\n",
    "        W_rot = np.rot90(np.rot90(self.W['val']))\n",
    "\n",
    "        dX = np.zeros(X.shape)\n",
    "        dW = np.zeros(self.W['val'].shape)\n",
    "        db = np.zeros(self.b['val'].shape)\n",
    "\n",
    "        # dW\n",
    "        for co in range(self.Cout):\n",
    "            for ci in range(Cin):\n",
    "                for h in range(self.F):\n",
    "                    for w in range(self.F):\n",
    "                        dW[co, ci, h, w] = np.sum(X[:,ci,h:h+H_,w:w+W_] * dout[:,co,:,:])\n",
    "\n",
    "        # db\n",
    "        for co in range(self.Cout):\n",
    "            db[co] = np.sum(dout[:,co,:,:])\n",
    "\n",
    "        dout_pad = np.pad(dout, ((0,0),(0,0),(self.F,self.F),(self.F,self.F)), 'constant')\n",
    "        #print(\"dout_pad.shape: \" + str(dout_pad.shape))\n",
    "        # dX\n",
    "        for n in range(N):\n",
    "            for ci in range(Cin):\n",
    "                for h in range(H):\n",
    "                    for w in range(W):\n",
    "                        #print(\"self.F.shape: %s\", self.F)\n",
    "                        #print(\"%s, W_rot[:,ci,:,:].shape: %s, dout_pad[n,:,h:h+self.F,w:w+self.F].shape: %s\" % ((n,ci,h,w),W_rot[:,ci,:,:].shape, dout_pad[n,:,h:h+self.F,w:w+self.F].shape))\n",
    "                        dX[n, ci, h, w] = np.sum(W_rot[:,ci,:,:] * dout_pad[n, :, h:h+self.F,w:w+self.F])\n",
    "\n",
    "        return dX\n",
    "\n",
    "class MaxPool():\n",
    "    def __init__(self, F, stride):\n",
    "        self.F = F\n",
    "        self.S = stride\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        # X: (N, Cin, H, W): maxpool along 3rd, 4th dim\n",
    "        (N,Cin,H,W) = X.shape\n",
    "        F = self.F\n",
    "        W_ = int(float(W)/F)\n",
    "        H_ = int(float(H)/F)\n",
    "        Y = np.zeros((N,Cin,W_,H_))\n",
    "        M = np.zeros(X.shape) # mask\n",
    "        for n in range(N):\n",
    "            for cin in range(Cin):\n",
    "                for w_ in range(W_):\n",
    "                    for h_ in range(H_):\n",
    "                        Y[n,cin,w_,h_] = np.max(X[n,cin,F*w_:F*(w_+1),F*h_:F*(h_+1)])\n",
    "                        i,j = np.unravel_index(X[n,cin,F*w_:F*(w_+1),F*h_:F*(h_+1)].argmax(), (F,F))\n",
    "                        M[n,cin,F*w_+i,F*h_+j] = 1\n",
    "        self.cache = M\n",
    "        return Y\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        M = self.cache\n",
    "        (N,Cin,H,W) = M.shape\n",
    "        dout = np.array(dout)\n",
    "        #print(\"dout.shape: %s, M.shape: %s\" % (dout.shape, M.shape))\n",
    "        dX = np.zeros(M.shape)\n",
    "        for n in range(N):\n",
    "            for c in range(Cin):\n",
    "                #print(\"(n,c): (%s,%s)\" % (n,c))\n",
    "                dX[n,c,:,:] = dout[n,c,:,:].repeat(2, axis=0).repeat(2, axis=1)\n",
    "        return dX*M\n",
    "\n",
    "def NLLLoss(Y_pred, Y_true):\n",
    "    \"\"\"\n",
    "    Negative log likelihood loss\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    N = Y_pred.shape[0]\n",
    "    M = np.sum(Y_pred*Y_true, axis=1)\n",
    "    for e in M:\n",
    "        #print(e)\n",
    "        if e == 0:\n",
    "            loss += 500\n",
    "        else:\n",
    "            loss += -np.log(e)\n",
    "    return loss/N\n",
    "\n",
    "class CrossEntropyLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get(self, Y_pred, Y_true):\n",
    "        N = Y_pred.shape[0]\n",
    "        softmax = Softmax()\n",
    "        prob = softmax._forward(Y_pred)\n",
    "        loss = NLLLoss(prob, Y_true)\n",
    "        Y_serial = np.argmax(Y_true, axis=1)\n",
    "        dout = prob.copy()\n",
    "        dout[np.arange(N), Y_serial] -= 1\n",
    "        return loss, dout\n",
    "\n",
    "class SoftmaxLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get(self, Y_pred, Y_true):\n",
    "        N = Y_pred.shape[0]\n",
    "        loss = NLLLoss(Y_pred, Y_true)\n",
    "        Y_serial = np.argmax(Y_true, axis=1)\n",
    "        dout = Y_pred.copy()\n",
    "        dout[np.arange(N), Y_serial] -= 1\n",
    "        return loss, dout\n",
    "\n",
    "class Net(metaclass=ABCMeta):\n",
    "    # Neural network super class\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, X):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward(self, dout):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_params(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_params(self, params):\n",
    "        pass\n",
    "\n",
    "\n",
    "class LeNet5(Net):\n",
    "    # LeNet5\n",
    "\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv(3, 6, 5)\n",
    "        self.ReLU1 = ReLU()\n",
    "        self.pool1 = MaxPool(2,2)\n",
    "        self.conv2 = Conv(6, 16, 5)\n",
    "        self.ReLU2 = ReLU()\n",
    "        self.pool2 = MaxPool(2,2)\n",
    "        self.FC1 = FC(16*5*5, 120)  # 64: 16*13*13\n",
    "        self.ReLU3 = ReLU()\n",
    "        self.FC2 = FC(120, 84)\n",
    "        self.ReLU4 = ReLU()\n",
    "        self.FC3 = FC(84, 50)\n",
    "        self.Softmax = Softmax()\n",
    "\n",
    "        self.p2_shape = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        h1 = self.conv1._forward(X)\n",
    "        a1 = self.ReLU1._forward(h1)\n",
    "        p1 = self.pool1._forward(a1)\n",
    "        h2 = self.conv2._forward(p1)\n",
    "        a2 = self.ReLU2._forward(h2)\n",
    "        p2 = self.pool2._forward(a2)\n",
    "        self.p2_shape = p2.shape\n",
    "        fl = p2.reshape(X.shape[0],-1) # Flatten\n",
    "        h3 = self.FC1._forward(fl)\n",
    "        a3 = self.ReLU3._forward(h3)\n",
    "        h4 = self.FC2._forward(a3)\n",
    "        a5 = self.ReLU4._forward(h4)\n",
    "        h5 = self.FC3._forward(a5)\n",
    "        a5 = self.Softmax._forward(h5)\n",
    "        return a5\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # dout = self.Softmax._backward(dout)\n",
    "        dout = self.FC3._backward(dout)\n",
    "        dout = self.ReLU4._backward(dout)\n",
    "        dout = self.FC2._backward(dout)\n",
    "        dout = self.ReLU3._backward(dout)\n",
    "        dout = self.FC1._backward(dout)\n",
    "        dout = dout.reshape(self.p2_shape) # reshape\n",
    "        dout = self.pool2._backward(dout)\n",
    "        dout = self.ReLU2._backward(dout)\n",
    "        dout = self.conv2._backward(dout)\n",
    "        dout = self.pool1._backward(dout)\n",
    "        dout = self.ReLU1._backward(dout)\n",
    "        dout = self.conv1._backward(dout)\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b] = params\n",
    "\n",
    "class SGD():\n",
    "    def __init__(self, params, lr=0.001, reg=0):\n",
    "        self.parameters = params\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.parameters:\n",
    "            param['val'] -= (self.lr*param['grad'] + self.reg*param['val'])\n",
    "\n",
    "class SGDMomentum():\n",
    "    def __init__(self, params, lr=0.001, momentum=0.99, reg=0):\n",
    "        self.l = len(params)\n",
    "        self.parameters = params\n",
    "        self.velocities = []\n",
    "        for param in self.parameters:\n",
    "            self.velocities.append(np.zeros(param['val'].shape))\n",
    "        self.lr = lr\n",
    "        self.rho = momentum\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for i in range(self.l):\n",
    "            self.velocities[i] = self.rho*self.velocities[i] + (1-self.rho)*self.parameters[i]['grad']\n",
    "            self.parameters[i]['val'] -= (self.lr*self.velocities[i] + self.reg*self.parameters[i]['val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data, labels, batch_size=64, shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_samples = data.shape[0]\n",
    "        self.num_batches = int(np.ceil(self.num_samples / self.batch_size))\n",
    "        self.indices = np.arange(self.num_samples)\n",
    "        self.current_batch = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current_batch >= self.num_batches:\n",
    "            self.current_batch = 0\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.indices)\n",
    "            raise StopIteration\n",
    "            \n",
    "        batch_indices = self.indices[self.current_batch*self.batch_size : (self.current_batch+1)*self.batch_size]\n",
    "        batch_data = self.data[batch_indices]\n",
    "        batch_labels = self.labels[batch_indices]\n",
    "        \n",
    "        self.current_batch += 1\n",
    "        \n",
    "        return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 64, D_out: 50\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "(1) Prepare Data: Load, Shuffle, Normalization, Batching, Preprocessing\n",
    "\"\"\"\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = resized_train_imgs, train_label, resized_test_imgs, test_label\n",
    "X_train, X_test = X_train/float(255), X_test/float(255)\n",
    "X_train -= np.mean(X_train)\n",
    "X_test -= np.mean(X_test)\n",
    "\n",
    "batch_size = 64\n",
    "# D_in = 784\n",
    "D_out = 50\n",
    "\n",
    "# print(\"batch_size: \" + str(batch_size) + \", D_in: \" + str(D_in) + \", D_out: \" + str(D_out))\n",
    "print(\"batch_size: \" + str(batch_size) + \", D_out: \" + str(D_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_fn(Y_pred, Y_true):\n",
    "    correct = np.argmax(Y_pred, axis=1) - np.argmax(Y_true, axis=1)\n",
    "    acc = (correct / len(Y_pred))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/990 [01:16<2:58:23, 10.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54937/2728223367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# forward, loss, backward, step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# loss, dout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY_batch\u001b[0m  \u001b[0;31m# pred - label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_54937/1599643228.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_54937/1599643228.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mh_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Lenet Forward Test ###\n",
    "model = LeNet5()\n",
    "train_dataloader = DataLoader(data=resized_train_imgs,\n",
    "                              labels=train_label,\n",
    "                              batch_size=64,\n",
    "                              shuffle=True)\n",
    "val_dataloader = DataLoader(data=resized_val_imgs,\n",
    "                            labels=val_label,\n",
    "                            batch_size=64,\n",
    "                            shuffle=True)\n",
    "\n",
    "train_losses = []\n",
    "# optim = SGDMomentum(params=model.get_params(), lr=1e-3, momentum=0.99, reg=0)\n",
    "optim = SGD(params=model.get_params(), lr=1e-3, reg=0)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Train\n",
    "EPOCHS = 5\n",
    "for i in range(EPOCHS):\n",
    "    print(f\"epoch: {i+1}\")\n",
    "    # train\n",
    "    losses_epoch, train_acc = 0, 0\n",
    "    with tqdm(total=dataloader.num_batches) as pbar:\n",
    "        for X_batch, Y_batch in train_dataloader:\n",
    "            # get batch, make onehot\n",
    "            # X_batch, Y_batch = get_batch(X_train, Y_train, batch_size)\n",
    "            Y_batch = MakeOneHot(Y_batch, D_out)\n",
    "\n",
    "            # forward, loss, backward, step\n",
    "            Y_pred = model.forward(X_batch)\n",
    "            loss, _ = criterion.get(Y_pred, Y_batch)  # loss, dout\n",
    "            dout = Y_pred - Y_batch  # pred - label\n",
    "            model.backward(dout)\n",
    "            optim.step()\n",
    "\n",
    "            # train accuracy\n",
    "            acc = acc_fn(Y_pred, Y_batch)\n",
    "\n",
    "            losses_epoch += loss\n",
    "            train_acc += acc\n",
    "            pbar.update(1)\n",
    "\n",
    "    losses_epoch /= train_dataloader.num_batches\n",
    "    train_acc /= train_dataloader.num_batches\n",
    "            \n",
    "    if i % 1 == 0:\n",
    "        print(\"%s%% epoch: %s, train loss: %s\" % (round(100*(i+1)/EPOCHS, 4), i+1, round(losses_epoch, 4)))\n",
    "        train_losses.append(losses_epoch)\n",
    "\n",
    "\n",
    "    # validation\n",
    "    val_loss, val_acc = 0, 0\n",
    "    for X_batch, Y_batch in val_dataloader:\n",
    "        # get batch, make onehot\n",
    "        # X_batch, Y_batch = get_batch(X_train, Y_train, batch_size)\n",
    "        Y_batch = MakeOneHot(Y_batch, D_out)\n",
    "\n",
    "        # forward, loss, backward, step\n",
    "        Y_pred = model.forward(X_batch)\n",
    "        loss, _ = criterion.get(Y_pred, Y_batch)  # loss, dout\n",
    "        dout = Y_pred - Y_batch  # pred - label\n",
    "        model.backward(dout)\n",
    "        optim.step()\n",
    "\n",
    "        # train accuracy\n",
    "        acc = acc_fn(Y_pred, Y_batch)\n",
    "\n",
    "        losses_epoch += loss\n",
    "        val_acc += acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save params\n",
    "weights = model.get_params()\n",
    "with open(\"weights.pkl\",\"wb\") as f:\n",
    "\tpickle.dump(weights, f)\n",
    "\n",
    "draw_losses(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SET ACC\n",
    "Y_pred = model.forward(X_train)\n",
    "result = np.argmax(Y_pred, axis=1) - Y_train\n",
    "result = list(result)\n",
    "print(\"TRAIN--> Correct: \" + str(result.count(0)) + \" out of \" + str(X_train.shape[0]) + \", acc=\" + str(result.count(0)/X_train.shape[0]))\n",
    "\n",
    "# TEST SET ACC\n",
    "Y_pred = model.forward(X_test)\n",
    "result = np.argmax(Y_pred, axis=1) - Y_test\n",
    "result = list(result)\n",
    "print(\"TEST--> Correct: \" + str(result.count(0)) + \" out of \" + str(X_test.shape[0]) + \", acc=\" + str(result.count(0)/X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% iter: 0, loss: 2.698777806248818\n",
      "0.4% iter: 100, loss: 1.5455440370735893\n",
      "0.8% iter: 200, loss: 1.0927210596032813\n",
      "1.2% iter: 300, loss: 0.9085808408557606\n",
      "1.6% iter: 400, loss: 0.7888468284883426\n",
      "2.0% iter: 500, loss: 0.5733515422738258\n",
      "2.4% iter: 600, loss: 0.6765259873610715\n",
      "2.8% iter: 700, loss: 0.6859925654300326\n",
      "3.2% iter: 800, loss: 0.4391278495697126\n",
      "3.6% iter: 900, loss: 0.3285070267415553\n",
      "4.0% iter: 1000, loss: 0.610436252172128\n",
      "4.4% iter: 1100, loss: 0.7696862664182191\n",
      "4.8% iter: 1200, loss: 0.520684541342298\n",
      "5.2% iter: 1300, loss: 0.44263307031246113\n",
      "5.6% iter: 1400, loss: 0.31153369938237924\n",
      "6.0% iter: 1500, loss: 0.4171841890843592\n",
      "6.4% iter: 1600, loss: 0.1963659279134646\n",
      "6.8% iter: 1700, loss: 0.33990764247818983\n",
      "7.2% iter: 1800, loss: 0.47742263403478435\n",
      "7.6% iter: 1900, loss: 0.29415906271152725\n",
      "8.0% iter: 2000, loss: 0.2501454798626019\n",
      "8.4% iter: 2100, loss: 0.30095897052426746\n",
      "8.8% iter: 2200, loss: 0.2982102319176414\n",
      "9.2% iter: 2300, loss: 0.264840147786447\n",
      "9.6% iter: 2400, loss: 0.34033001897734244\n",
      "10.0% iter: 2500, loss: 0.4767389901345191\n",
      "10.4% iter: 2600, loss: 0.1383816800011712\n",
      "10.8% iter: 2700, loss: 0.41307390175656467\n",
      "11.2% iter: 2800, loss: 0.22051608716935345\n",
      "11.6% iter: 2900, loss: 0.3575189213921308\n",
      "12.0% iter: 3000, loss: 0.37528469964175143\n",
      "12.4% iter: 3100, loss: 0.22964413779508633\n",
      "12.8% iter: 3200, loss: 0.5267601180959031\n",
      "13.2% iter: 3300, loss: 0.2511118263352808\n",
      "13.6% iter: 3400, loss: 0.2907733319569403\n",
      "14.0% iter: 3500, loss: 0.9550192815274927\n",
      "14.4% iter: 3600, loss: 0.2955837733985672\n",
      "14.8% iter: 3700, loss: 0.2538047244287388\n",
      "15.2% iter: 3800, loss: 0.523986130925581\n",
      "15.6% iter: 3900, loss: 0.19978365881365653\n",
      "16.0% iter: 4000, loss: 0.41995068714579004\n",
      "16.4% iter: 4100, loss: 0.34964589486652664\n",
      "16.8% iter: 4200, loss: 0.3674126920938494\n",
      "17.2% iter: 4300, loss: 0.4042229314027755\n",
      "17.6% iter: 4400, loss: 0.22377846341291802\n",
      "18.0% iter: 4500, loss: 0.24407447766756266\n",
      "18.4% iter: 4600, loss: 0.18735223747540017\n",
      "18.8% iter: 4700, loss: 0.4223669044091284\n",
      "19.2% iter: 4800, loss: 0.40013375835224707\n",
      "19.6% iter: 4900, loss: 0.34777796053955445\n",
      "20.0% iter: 5000, loss: 0.6015791095110752\n",
      "20.4% iter: 5100, loss: 0.19459409316142554\n",
      "20.8% iter: 5200, loss: 0.15076536487838452\n",
      "21.2% iter: 5300, loss: 0.20579434045877992\n",
      "21.6% iter: 5400, loss: 0.3718204581584984\n",
      "22.0% iter: 5500, loss: 0.548382066027687\n",
      "22.4% iter: 5600, loss: 0.43780945844318203\n",
      "22.8% iter: 5700, loss: 0.17826045555875633\n",
      "23.2% iter: 5800, loss: 0.32746925128305987\n",
      "23.6% iter: 5900, loss: 0.35087402479903806\n",
      "24.0% iter: 6000, loss: 0.2257164733598832\n",
      "24.4% iter: 6100, loss: 0.5194531979740806\n",
      "24.8% iter: 6200, loss: 0.181872203386988\n",
      "25.2% iter: 6300, loss: 0.1881219811749211\n",
      "25.6% iter: 6400, loss: 0.24745751072542185\n",
      "26.0% iter: 6500, loss: 0.18397270803202043\n",
      "26.4% iter: 6600, loss: 0.25597577692418977\n",
      "26.8% iter: 6700, loss: 0.1235329947305034\n",
      "27.2% iter: 6800, loss: 0.20952419329982166\n",
      "27.6% iter: 6900, loss: 0.6599908740022151\n",
      "28.0% iter: 7000, loss: 0.15373821014077974\n",
      "28.4% iter: 7100, loss: 0.1949196808363591\n",
      "28.8% iter: 7200, loss: 0.4130489787226575\n",
      "29.2% iter: 7300, loss: 0.3651063798869089\n",
      "29.6% iter: 7400, loss: 0.44791479351592284\n",
      "30.0% iter: 7500, loss: 0.23472044531766034\n",
      "30.4% iter: 7600, loss: 0.17382561691539306\n",
      "30.8% iter: 7700, loss: 0.3133313167215577\n",
      "31.2% iter: 7800, loss: 0.12863491225688814\n",
      "31.6% iter: 7900, loss: 0.18864253597734018\n",
      "32.0% iter: 8000, loss: 0.37679249193446557\n",
      "32.4% iter: 8100, loss: 0.1448285689231551\n",
      "32.8% iter: 8200, loss: 0.27830828061133683\n",
      "33.2% iter: 8300, loss: 0.3294328540777346\n",
      "33.6% iter: 8400, loss: 0.37772494936298795\n",
      "34.0% iter: 8500, loss: 0.38245202921801025\n",
      "34.4% iter: 8600, loss: 0.3985191360795628\n",
      "34.8% iter: 8700, loss: 0.1685135066239028\n",
      "35.2% iter: 8800, loss: 0.21696901595783213\n",
      "35.6% iter: 8900, loss: 0.19567828286274702\n",
      "36.0% iter: 9000, loss: 0.16645087931935773\n",
      "36.4% iter: 9100, loss: 0.2944282061635168\n",
      "36.8% iter: 9200, loss: 0.20181496040517466\n",
      "37.2% iter: 9300, loss: 0.2229392553261542\n",
      "37.6% iter: 9400, loss: 0.2313102507676738\n",
      "38.0% iter: 9500, loss: 0.19334061932513724\n",
      "38.4% iter: 9600, loss: 0.32595679576669456\n",
      "38.8% iter: 9700, loss: 0.08806618456907209\n",
      "39.2% iter: 9800, loss: 0.2941503968854204\n",
      "39.6% iter: 9900, loss: 0.5030104629000937\n",
      "40.0% iter: 10000, loss: 0.30508930442256077\n",
      "40.4% iter: 10100, loss: 0.2977974457926525\n",
      "40.8% iter: 10200, loss: 0.4427095739528648\n",
      "41.2% iter: 10300, loss: 0.1408156510214649\n",
      "41.6% iter: 10400, loss: 0.47704377581695484\n",
      "42.0% iter: 10500, loss: 0.20849519038493097\n",
      "42.4% iter: 10600, loss: 0.17478602703230775\n",
      "42.8% iter: 10700, loss: 0.36367506385363096\n",
      "43.2% iter: 10800, loss: 0.4463735987582797\n",
      "43.6% iter: 10900, loss: 0.3092368928920954\n",
      "44.0% iter: 11000, loss: 0.19346138958465606\n",
      "44.4% iter: 11100, loss: 0.36647781445159766\n",
      "44.8% iter: 11200, loss: 0.2618162769726168\n",
      "45.2% iter: 11300, loss: 0.28473772283705395\n",
      "45.6% iter: 11400, loss: 0.34599596883355793\n",
      "46.0% iter: 11500, loss: 0.2520765886945045\n",
      "46.4% iter: 11600, loss: 0.23000606373431984\n",
      "46.8% iter: 11700, loss: 0.14464097317386224\n",
      "47.2% iter: 11800, loss: 0.3341562390147643\n",
      "47.6% iter: 11900, loss: 0.529016786206018\n",
      "48.0% iter: 12000, loss: 0.11870551623291553\n",
      "48.4% iter: 12100, loss: 0.2392124819653994\n",
      "48.8% iter: 12200, loss: 0.39733849073724975\n",
      "49.2% iter: 12300, loss: 0.26428223768446346\n",
      "49.6% iter: 12400, loss: 0.16945281777575355\n",
      "50.0% iter: 12500, loss: 0.09828274221666763\n",
      "50.4% iter: 12600, loss: 0.20807866646561476\n",
      "50.8% iter: 12700, loss: 0.2753031341646908\n",
      "51.2% iter: 12800, loss: 0.3121080475698356\n",
      "51.6% iter: 12900, loss: 0.1577695957423895\n",
      "52.0% iter: 13000, loss: 0.3596741181718713\n",
      "52.4% iter: 13100, loss: 0.13978008262456953\n",
      "52.8% iter: 13200, loss: 0.31072091272965136\n",
      "53.2% iter: 13300, loss: 0.1512789100319944\n",
      "53.6% iter: 13400, loss: 0.3051982144489994\n",
      "54.0% iter: 13500, loss: 0.07611219585920809\n",
      "54.4% iter: 13600, loss: 0.42263351107396135\n",
      "54.8% iter: 13700, loss: 0.23732016105398382\n",
      "55.2% iter: 13800, loss: 0.16281138556592198\n",
      "55.6% iter: 13900, loss: 0.2525171791776275\n",
      "56.0% iter: 14000, loss: 0.19067325315009456\n",
      "56.4% iter: 14100, loss: 0.111759243864937\n",
      "56.8% iter: 14200, loss: 0.48766678558552834\n",
      "57.2% iter: 14300, loss: 0.4092242977161202\n",
      "57.6% iter: 14400, loss: 0.2148885164530732\n",
      "58.0% iter: 14500, loss: 0.4285374953894981\n",
      "58.4% iter: 14600, loss: 0.22168952912433598\n",
      "58.8% iter: 14700, loss: 0.13220548348109182\n",
      "59.2% iter: 14800, loss: 0.3132964195178952\n",
      "59.6% iter: 14900, loss: 0.15390236467312182\n",
      "60.0% iter: 15000, loss: 0.10225472968811963\n",
      "60.4% iter: 15100, loss: 0.10900264314270164\n",
      "60.8% iter: 15200, loss: 0.2537818232567888\n",
      "61.2% iter: 15300, loss: 0.1725103252101583\n",
      "61.6% iter: 15400, loss: 0.22660430143555255\n",
      "62.0% iter: 15500, loss: 0.22660951343848282\n",
      "62.4% iter: 15600, loss: 0.22341548653929066\n",
      "62.8% iter: 15700, loss: 0.17876507907343503\n",
      "63.2% iter: 15800, loss: 0.4478470873781933\n",
      "63.6% iter: 15900, loss: 0.10304359574514325\n",
      "64.0% iter: 16000, loss: 0.23857997775842146\n",
      "64.4% iter: 16100, loss: 0.16647202188487895\n",
      "64.8% iter: 16200, loss: 0.36900149918573544\n",
      "65.2% iter: 16300, loss: 0.2763714023596188\n",
      "65.6% iter: 16400, loss: 0.371459194696777\n",
      "66.0% iter: 16500, loss: 0.2935350752745115\n",
      "66.4% iter: 16600, loss: 0.14748200085031746\n",
      "66.8% iter: 16700, loss: 0.2670684314179623\n",
      "67.2% iter: 16800, loss: 0.2142740118020102\n",
      "67.6% iter: 16900, loss: 0.14497387981887525\n",
      "68.0% iter: 17000, loss: 0.26919468980461736\n",
      "68.4% iter: 17100, loss: 0.12983361042782568\n",
      "68.8% iter: 17200, loss: 0.27105134483585963\n",
      "69.2% iter: 17300, loss: 0.19746976664435043\n",
      "69.6% iter: 17400, loss: 0.1711385680598644\n",
      "70.0% iter: 17500, loss: 0.3568314822337306\n",
      "70.4% iter: 17600, loss: 0.2497237139041457\n",
      "70.8% iter: 17700, loss: 0.16297203857061351\n",
      "71.2% iter: 17800, loss: 0.1737617634245427\n",
      "71.6% iter: 17900, loss: 0.205333608109198\n",
      "72.0% iter: 18000, loss: 0.15451074714297122\n",
      "72.4% iter: 18100, loss: 0.10759924754205259\n",
      "72.8% iter: 18200, loss: 0.1767205441725347\n",
      "73.2% iter: 18300, loss: 0.3064597660882026\n",
      "73.6% iter: 18400, loss: 0.12329318265203276\n",
      "74.0% iter: 18500, loss: 0.32715514853426086\n",
      "74.4% iter: 18600, loss: 0.20930026140242114\n",
      "74.8% iter: 18700, loss: 0.5083795619125118\n",
      "75.2% iter: 18800, loss: 0.31456369555423236\n",
      "75.6% iter: 18900, loss: 0.20153723175507282\n",
      "76.0% iter: 19000, loss: 0.22137275597195216\n",
      "76.4% iter: 19100, loss: 0.26449654736388334\n",
      "76.8% iter: 19200, loss: 0.1713681162329917\n",
      "77.2% iter: 19300, loss: 0.1149508267267424\n",
      "77.6% iter: 19400, loss: 0.09540043269852537\n",
      "78.0% iter: 19500, loss: 0.17504452827703654\n",
      "78.4% iter: 19600, loss: 0.15825371331402163\n",
      "78.8% iter: 19700, loss: 0.07516274529000944\n",
      "79.2% iter: 19800, loss: 0.12254129475153266\n",
      "79.6% iter: 19900, loss: 0.18120820253382014\n",
      "80.0% iter: 20000, loss: 0.37244250959418074\n",
      "80.4% iter: 20100, loss: 0.15066719948992838\n",
      "80.8% iter: 20200, loss: 0.174657396009331\n",
      "81.2% iter: 20300, loss: 0.15024131839637164\n",
      "81.6% iter: 20400, loss: 0.1658820759956157\n",
      "82.0% iter: 20500, loss: 0.28675640295909915\n",
      "82.4% iter: 20600, loss: 0.21676701963101655\n",
      "82.8% iter: 20700, loss: 0.07893230007549551\n",
      "83.2% iter: 20800, loss: 0.2130367091990291\n",
      "83.6% iter: 20900, loss: 0.1966061605243316\n",
      "84.0% iter: 21000, loss: 0.09904176818258785\n",
      "84.4% iter: 21100, loss: 0.4326826780185301\n",
      "84.8% iter: 21200, loss: 0.19493293323727517\n",
      "85.2% iter: 21300, loss: 0.2096980671655543\n",
      "85.6% iter: 21400, loss: 0.15218472345534864\n",
      "86.0% iter: 21500, loss: 0.14035505099109263\n",
      "86.4% iter: 21600, loss: 0.1899143553073426\n",
      "86.8% iter: 21700, loss: 0.12638119510776702\n",
      "87.2% iter: 21800, loss: 0.19717507526480654\n",
      "87.6% iter: 21900, loss: 0.2039222410778832\n",
      "88.0% iter: 22000, loss: 0.3205950542074657\n",
      "88.4% iter: 22100, loss: 0.16254976515673594\n",
      "88.8% iter: 22200, loss: 0.13932051016257993\n",
      "89.2% iter: 22300, loss: 0.10380060649816865\n",
      "89.6% iter: 22400, loss: 0.24949618913123706\n",
      "90.0% iter: 22500, loss: 0.24476079697814435\n",
      "90.4% iter: 22600, loss: 0.17901414288040973\n",
      "90.8% iter: 22700, loss: 0.17904169562405373\n",
      "91.2% iter: 22800, loss: 0.252727324039555\n",
      "91.6% iter: 22900, loss: 0.17562925806195026\n",
      "92.0% iter: 23000, loss: 0.16736912353610184\n",
      "92.4% iter: 23100, loss: 0.15051337368900125\n",
      "92.8% iter: 23200, loss: 0.17088357093483714\n",
      "93.2% iter: 23300, loss: 0.21475723410283368\n",
      "93.6% iter: 23400, loss: 0.06304747046119097\n",
      "94.0% iter: 23500, loss: 0.35241774672519727\n",
      "94.4% iter: 23600, loss: 0.1846044642535831\n",
      "94.8% iter: 23700, loss: 0.25310231219438223\n",
      "95.2% iter: 23800, loss: 0.20671295487926855\n",
      "95.6% iter: 23900, loss: 0.11068618415753931\n",
      "96.0% iter: 24000, loss: 0.2169351536343727\n",
      "96.4% iter: 24100, loss: 0.08136574442114008\n",
      "96.8% iter: 24200, loss: 0.2898881764853306\n",
      "97.2% iter: 24300, loss: 0.23528294475989103\n",
      "97.6% iter: 24400, loss: 0.1701078246405516\n",
      "98.0% iter: 24500, loss: 0.062178645554969575\n",
      "98.4% iter: 24600, loss: 0.10823988206244164\n",
      "98.8% iter: 24700, loss: 0.16412064001392504\n",
      "99.2% iter: 24800, loss: 0.19820791225571463\n",
      "99.6% iter: 24900, loss: 0.10210760840840621\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN--> Correct: 57107 out of 60000, acc=0.9517833333333333\n",
      "TEST--> Correct: 9510 out of 10000, acc=0.951\n"
     ]
    }
   ],
   "source": [
    "### TWO LAYER NET FORWARD TEST ###\n",
    "#H=400\n",
    "#model = nn.TwoLayerNet(batch_size, D_in, H, D_out)\n",
    "H1=300\n",
    "H2=100\n",
    "model = ThreeLayerNet(batch_size, D_in, H1, H2, D_out)\n",
    "\n",
    "\n",
    "losses = []\n",
    "#optim = optimizer.SGD(model.get_params(), lr=0.0001, reg=0)\n",
    "optim = SGDMomentum(model.get_params(), lr=0.0001, momentum=0.80, reg=0.00003)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# TRAIN\n",
    "ITER = 25000\n",
    "for i in range(ITER):\n",
    "\t# get batch, make onehot\n",
    "\tX_batch, Y_batch = get_batch(X_train, Y_train, batch_size)\n",
    "\tY_batch = MakeOneHot(Y_batch, D_out)\n",
    "\n",
    "\t# forward, loss, backward, step\n",
    "\tY_pred = model.forward(X_batch)\n",
    "\tloss, dout = criterion.get(Y_pred, Y_batch)\n",
    "\tmodel.backward(dout)\n",
    "\toptim.step()\n",
    "\n",
    "\tif i % 100 == 0:\n",
    "\t\tprint(\"%s%% iter: %s, loss: %s\" % (100*i/ITER,i, loss))\n",
    "\t\tlosses.append(loss)\n",
    "\n",
    "\n",
    "# save params\n",
    "weights = model.get_params()\n",
    "with open(\"weights.pkl\",\"wb\") as f:\n",
    "\tpickle.dump(weights, f)\n",
    "\n",
    "draw_losses(losses)\n",
    "\n",
    "\n",
    "\n",
    "# TRAIN SET ACC\n",
    "Y_pred = model.forward(X_train)\n",
    "result = np.argmax(Y_pred, axis=1) - Y_train\n",
    "result = list(result)\n",
    "print(\"TRAIN--> Correct: \" + str(result.count(0)) + \" out of \" + str(X_train.shape[0]) + \", acc=\" + str(result.count(0)/X_train.shape[0]))\n",
    "\n",
    "# TEST SET ACC\n",
    "Y_pred = model.forward(X_test)\n",
    "result = np.argmax(Y_pred, axis=1) - Y_test\n",
    "result = list(result)\n",
    "print(\"TEST--> Correct: \" + str(result.count(0)) + \" out of \" + str(X_test.shape[0]) + \", acc=\" + str(result.count(0)/X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "Y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from abc import ABCMeta, abstractmethod\n",
    "\n",
    "# filename = [\n",
    "# \t[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
    "# \t[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
    "# \t[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
    "# \t[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
    "# ]\n",
    "\n",
    "# def download_mnist():\n",
    "#     base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "#     for name in filename:\n",
    "#         print(\"Downloading \"+name[1]+\"...\")\n",
    "#         request.urlretrieve(base_url+name[1], name[1])\n",
    "#     print(\"Download complete.\")\n",
    "\n",
    "# def save_mnist():\n",
    "#     mnist = {}\n",
    "#     for name in filename[:2]:\n",
    "#         with gzip.open(name[1], 'rb') as f:\n",
    "#             mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
    "#     for name in filename[-2:]:\n",
    "#         with gzip.open(name[1], 'rb') as f:\n",
    "#             mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "#     with open(\"mnist.pkl\", 'wb') as f:\n",
    "#         pickle.dump(mnist,f)\n",
    "#     print(\"Save complete.\")\n",
    "\n",
    "# def init():\n",
    "#     download_mnist()\n",
    "#     save_mnist()\n",
    "\n",
    "# def load():\n",
    "#     with open(\"mnist.pkl\",'rb') as f:\n",
    "#         mnist = pickle.load(f)\n",
    "#     return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
    "\n",
    "# def MakeOneHot(Y, D_out):\n",
    "#     N = Y.shape[0]\n",
    "#     Z = np.zeros((N, D_out))\n",
    "#     Z[np.arange(N), Y] = 1\n",
    "#     return Z\n",
    "\n",
    "# def draw_losses(losses):\n",
    "#     t = np.arange(len(losses))\n",
    "#     plt.plot(t, losses)\n",
    "#     plt.show()\n",
    "\n",
    "# def get_batch(X, Y, batch_size):\n",
    "#     N = len(X)\n",
    "#     i = random.randint(1, N-batch_size)\n",
    "#     return X[i:i+batch_size], Y[i:i+batch_size]\n",
    "\n",
    "# class FC():\n",
    "#     \"\"\"\n",
    "#     Fully connected layer\n",
    "#     \"\"\"\n",
    "#     def __init__(self, D_in, D_out):\n",
    "#         #print(\"Build FC\")\n",
    "#         self.cache = None\n",
    "#         #self.W = {'val': np.random.randn(D_in, D_out), 'grad': 0}\n",
    "#         self.W = {'val': np.random.normal(0.0, np.sqrt(2/D_in), (D_in,D_out)), 'grad': 0}\n",
    "#         self.b = {'val': np.random.randn(D_out), 'grad': 0}\n",
    "\n",
    "#     def _forward(self, X):\n",
    "#         #print(\"FC: _forward\")\n",
    "#         out = np.dot(X, self.W['val']) + self.b['val']\n",
    "#         self.cache = X\n",
    "#         return out\n",
    "\n",
    "#     def _backward(self, dout):\n",
    "#         #print(\"FC: _backward\")\n",
    "#         X = self.cache\n",
    "#         dX = np.dot(dout, self.W['val'].T).reshape(X.shape)\n",
    "#         self.W['grad'] = np.dot(X.reshape(X.shape[0], np.prod(X.shape[1:])).T, dout)\n",
    "#         self.b['grad'] = np.sum(dout, axis=0)\n",
    "#         #self._update_params()\n",
    "#         return dX\n",
    "\n",
    "#     def _update_params(self, lr=0.001):\n",
    "#         # Update the parameters\n",
    "#         self.W['val'] -= lr*self.W['grad']\n",
    "#         self.b['val'] -= lr*self.b['grad']\n",
    "\n",
    "# class ReLU():\n",
    "#     \"\"\"\n",
    "#     ReLU activation layer\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         #print(\"Build ReLU\")\n",
    "#         self.cache = None\n",
    "\n",
    "#     def _forward(self, X):\n",
    "#         #print(\"ReLU: _forward\")\n",
    "#         out = np.maximum(0, X)\n",
    "#         self.cache = X\n",
    "#         return out\n",
    "\n",
    "#     def _backward(self, dout):\n",
    "#         #print(\"ReLU: _backward\")\n",
    "#         X = self.cache\n",
    "#         dX = np.array(dout, copy=True)\n",
    "#         dX[X <= 0] = 0\n",
    "#         return dX\n",
    "\n",
    "# class Sigmoid():\n",
    "#     \"\"\"\n",
    "#     Sigmoid activation layer\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         self.cache = None\n",
    "\n",
    "#     def _forward(self, X):\n",
    "#         self.cache = X\n",
    "#         return 1 / (1 + np.exp(-X))\n",
    "\n",
    "#     def _backward(self, dout):\n",
    "#         X = self.cache\n",
    "#         dX = dout*X*(1-X)\n",
    "#         return dX\n",
    "\n",
    "# class tanh():\n",
    "#     \"\"\"\n",
    "#     tanh activation layer\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         self.cache = X\n",
    "\n",
    "#     def _forward(self, X):\n",
    "#         self.cache = X\n",
    "#         return np.tanh(X)\n",
    "\n",
    "#     def _backward(self, X):\n",
    "#         X = self.cache\n",
    "#         dX = dout*(1 - np.tanh(X)**2)\n",
    "#         return dX\n",
    "\n",
    "# class Softmax():\n",
    "#     \"\"\"\n",
    "#     Softmax activation layer\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         #print(\"Build Softmax\")\n",
    "#         self.cache = None\n",
    "\n",
    "#     def _forward(self, X):\n",
    "#         #print(\"Softmax: _forward\")\n",
    "#         maxes = np.amax(X, axis=1)\n",
    "#         maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "#         Y = np.exp(X - maxes)\n",
    "#         Z = Y / np.sum(Y, axis=1).reshape(Y.shape[0], 1)\n",
    "#         self.cache = (X, Y, Z)\n",
    "#         return Z # distribution\n",
    "\n",
    "#     def _backward(self, dout):\n",
    "#         X, Y, Z = self.cache\n",
    "#         dZ = np.zeros(X.shape)\n",
    "#         dY = np.zeros(X.shape)\n",
    "#         dX = np.zeros(X.shape)\n",
    "#         N = X.shape[0]\n",
    "#         for n in range(N):\n",
    "#             i = np.argmax(Z[n])\n",
    "#             dZ[n,:] = np.diag(Z[n]) - np.outer(Z[n],Z[n])\n",
    "#             M = np.zeros((N,N))\n",
    "#             M[:,i] = 1\n",
    "#             dY[n,:] = np.eye(N) - M\n",
    "#         dX = np.dot(dout,dZ)\n",
    "#         dX = np.dot(dX,dY)\n",
    "#         return dX\n",
    "\n",
    "# class Dropout():\n",
    "#     \"\"\"\n",
    "#     Dropout layer\n",
    "#     \"\"\"\n",
    "#     def __init__(self, p=1):\n",
    "#         self.cache = None\n",
    "#         self.p = p\n",
    "\n",
    "#     def _forward(self, X):\n",
    "#         M = (np.random.rand(*X.shape) < self.p) / self.p\n",
    "#         self.cache = X, M\n",
    "#         return X*M\n",
    "\n",
    "#     def _backward(self, dout):\n",
    "#         X, M = self.cache\n",
    "#         dX = dout*M/self.p\n",
    "#         return dX\n",
    "\n",
    "# class Conv():\n",
    "#     \"\"\"\n",
    "#     Conv layer\n",
    "#     \"\"\"\n",
    "#     def __init__(self, Cin, Cout, F, stride=1, padding=0, bias=True):\n",
    "#         self.Cin = Cin\n",
    "#         self.Cout = Cout\n",
    "#         self.F = F\n",
    "#         self.S = stride\n",
    "#         #self.W = {'val': np.random.randn(Cout, Cin, F, F), 'grad': 0}\n",
    "#         self.W = {'val': np.random.normal(0.0,np.sqrt(2/Cin),(Cout,Cin,F,F)), 'grad': 0} # Xavier Initialization\n",
    "#         self.b = {'val': np.random.randn(Cout), 'grad': 0}\n",
    "#         self.cache = None\n",
    "#         self.pad = padding\n",
    "\n",
    "#     def _forward(self, X):\n",
    "#         X = np.pad(X, ((0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)), 'constant')\n",
    "#         (N, Cin, H, W) = X.shape\n",
    "#         H_ = H - self.F + 1\n",
    "#         W_ = W - self.F + 1\n",
    "#         Y = np.zeros((N, self.Cout, H_, W_))\n",
    "\n",
    "#         for n in range(N):\n",
    "#             for c in range(self.Cout):\n",
    "#                 for h in range(H_):\n",
    "#                     for w in range(W_):\n",
    "#                         Y[n, c, h, w] = np.sum(X[n, :, h:h+self.F, w:w+self.F] * self.W['val'][c, :, :, :]) + self.b['val'][c]\n",
    "\n",
    "#         self.cache = X\n",
    "#         return Y\n",
    "\n",
    "#     def _backward(self, dout):\n",
    "#         # dout (N,Cout,H_,W_)\n",
    "#         # W (Cout, Cin, F, F)\n",
    "#         X = self.cache\n",
    "#         (N, Cin, H, W) = X.shape\n",
    "#         H_ = H - self.F + 1\n",
    "#         W_ = W - self.F + 1\n",
    "#         W_rot = np.rot90(np.rot90(self.W['val']))\n",
    "\n",
    "#         dX = np.zeros(X.shape)\n",
    "#         dW = np.zeros(self.W['val'].shape)\n",
    "#         db = np.zeros(self.b['val'].shape)\n",
    "\n",
    "#         # dW\n",
    "#         for co in range(self.Cout):\n",
    "#             for ci in range(Cin):\n",
    "#                 for h in range(self.F):\n",
    "#                     for w in range(self.F):\n",
    "#                         dW[co, ci, h, w] = np.sum(X[:,ci,h:h+H_,w:w+W_] * dout[:,co,:,:])\n",
    "\n",
    "#         # db\n",
    "#         for co in range(self.Cout):\n",
    "#             db[co] = np.sum(dout[:,co,:,:])\n",
    "\n",
    "#         dout_pad = np.pad(dout, ((0,0),(0,0),(self.F,self.F),(self.F,self.F)), 'constant')\n",
    "#         #print(\"dout_pad.shape: \" + str(dout_pad.shape))\n",
    "#         # dX\n",
    "#         for n in range(N):\n",
    "#             for ci in range(Cin):\n",
    "#                 for h in range(H):\n",
    "#                     for w in range(W):\n",
    "#                         #print(\"self.F.shape: %s\", self.F)\n",
    "#                         #print(\"%s, W_rot[:,ci,:,:].shape: %s, dout_pad[n,:,h:h+self.F,w:w+self.F].shape: %s\" % ((n,ci,h,w),W_rot[:,ci,:,:].shape, dout_pad[n,:,h:h+self.F,w:w+self.F].shape))\n",
    "#                         dX[n, ci, h, w] = np.sum(W_rot[:,ci,:,:] * dout_pad[n, :, h:h+self.F,w:w+self.F])\n",
    "\n",
    "#         return dX\n",
    "\n",
    "# class MaxPool():\n",
    "#     def __init__(self, F, stride):\n",
    "#         self.F = F\n",
    "#         self.S = stride\n",
    "#         self.cache = None\n",
    "\n",
    "#     def _forward(self, X):\n",
    "#         # X: (N, Cin, H, W): maxpool along 3rd, 4th dim\n",
    "#         (N,Cin,H,W) = X.shape\n",
    "#         F = self.F\n",
    "#         W_ = int(float(W)/F)\n",
    "#         H_ = int(float(H)/F)\n",
    "#         Y = np.zeros((N,Cin,W_,H_))\n",
    "#         M = np.zeros(X.shape) # mask\n",
    "#         for n in range(N):\n",
    "#             for cin in range(Cin):\n",
    "#                 for w_ in range(W_):\n",
    "#                     for h_ in range(H_):\n",
    "#                         Y[n,cin,w_,h_] = np.max(X[n,cin,F*w_:F*(w_+1),F*h_:F*(h_+1)])\n",
    "#                         i,j = np.unravel_index(X[n,cin,F*w_:F*(w_+1),F*h_:F*(h_+1)].argmax(), (F,F))\n",
    "#                         M[n,cin,F*w_+i,F*h_+j] = 1\n",
    "#         self.cache = M\n",
    "#         return Y\n",
    "\n",
    "#     def _backward(self, dout):\n",
    "#         M = self.cache\n",
    "#         (N,Cin,H,W) = M.shape\n",
    "#         dout = np.array(dout)\n",
    "#         #print(\"dout.shape: %s, M.shape: %s\" % (dout.shape, M.shape))\n",
    "#         dX = np.zeros(M.shape)\n",
    "#         for n in range(N):\n",
    "#             for c in range(Cin):\n",
    "#                 #print(\"(n,c): (%s,%s)\" % (n,c))\n",
    "#                 dX[n,c,:,:] = dout[n,c,:,:].repeat(2, axis=0).repeat(2, axis=1)\n",
    "#         return dX*M\n",
    "\n",
    "# def NLLLoss(Y_pred, Y_true):\n",
    "#     \"\"\"\n",
    "#     Negative log likelihood loss\n",
    "#     \"\"\"\n",
    "#     loss = 0.0\n",
    "#     N = Y_pred.shape[0]\n",
    "#     M = np.sum(Y_pred*Y_true, axis=1)\n",
    "#     for e in M:\n",
    "#         #print(e)\n",
    "#         if e == 0:\n",
    "#             loss += 500\n",
    "#         else:\n",
    "#             loss += -np.log(e)\n",
    "#     return loss/N\n",
    "\n",
    "# class CrossEntropyLoss():\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def get(self, Y_pred, Y_true):\n",
    "#         N = Y_pred.shape[0]\n",
    "#         softmax = Softmax()\n",
    "#         prob = softmax._forward(Y_pred)\n",
    "#         loss = NLLLoss(prob, Y_true)\n",
    "#         Y_serial = np.argmax(Y_true, axis=1)\n",
    "#         dout = prob.copy()\n",
    "#         dout[np.arange(N), Y_serial] -= 1\n",
    "#         return loss, dout\n",
    "\n",
    "# class SoftmaxLoss():\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def get(self, Y_pred, Y_true):\n",
    "#         N = Y_pred.shape[0]\n",
    "#         loss = NLLLoss(Y_pred, Y_true)\n",
    "#         Y_serial = np.argmax(Y_true, axis=1)\n",
    "#         dout = Y_pred.copy()\n",
    "#         dout[np.arange(N), Y_serial] -= 1\n",
    "#         return loss, dout\n",
    "\n",
    "# class Net(metaclass=ABCMeta):\n",
    "#     # Neural network super class\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def forward(self, X):\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def backward(self, dout):\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def get_params(self):\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def set_params(self, params):\n",
    "#         pass\n",
    "\n",
    "\n",
    "# class TwoLayerNet(Net):\n",
    "\n",
    "#     #Simple 2 layer NN\n",
    "\n",
    "#     def __init__(self, N, D_in, H, D_out, weights=''):\n",
    "#         self.FC1 = FC(D_in, H)\n",
    "#         self.ReLU1 = ReLU()\n",
    "#         self.FC2 = FC(H, D_out)\n",
    "\n",
    "#         if weights == '':\n",
    "#             pass\n",
    "#         else:\n",
    "#             with open(weights,'rb') as f:\n",
    "#                 params = pickle.load(f)\n",
    "#                 self.set_params(params)\n",
    "\n",
    "#     def forward(self, X):\n",
    "#         h1 = self.FC1._forward(X)\n",
    "#         a1 = self.ReLU1._forward(h1)\n",
    "#         h2 = self.FC2._forward(a1)\n",
    "#         return h2\n",
    "\n",
    "#     def backward(self, dout):\n",
    "#         dout = self.FC2._backward(dout)\n",
    "#         dout = self.ReLU1._backward(dout)\n",
    "#         dout = self.FC1._backward(dout)\n",
    "\n",
    "#     def get_params(self):\n",
    "#         return [self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b]\n",
    "\n",
    "#     def set_params(self, params):\n",
    "#         [self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b] = params\n",
    "\n",
    "\n",
    "# class ThreeLayerNet(Net):\n",
    "\n",
    "#     #Simple 3 layer NN\n",
    "\n",
    "#     def __init__(self, N, D_in, H1, H2, D_out, weights=''):\n",
    "#         self.FC1 = FC(D_in, H1)\n",
    "#         self.ReLU1 = ReLU()\n",
    "#         self.FC2 = FC(H1, H2)\n",
    "#         self.ReLU2 = ReLU()\n",
    "#         self.FC3 = FC(H2, D_out)\n",
    "\n",
    "#         if weights == '':\n",
    "#             pass\n",
    "#         else:\n",
    "#             with open(weights,'rb') as f:\n",
    "#                 params = pickle.load(f)\n",
    "#                 self.set_params(params)\n",
    "\n",
    "#     def forward(self, X):\n",
    "#         h1 = self.FC1._forward(X)\n",
    "#         a1 = self.ReLU1._forward(h1)\n",
    "#         h2 = self.FC2._forward(a1)\n",
    "#         a2 = self.ReLU2._forward(h2)\n",
    "#         h3 = self.FC3._forward(a2)\n",
    "#         return h3\n",
    "\n",
    "#     def backward(self, dout):\n",
    "#         dout = self.FC3._backward(dout)\n",
    "#         dout = self.ReLU2._backward(dout)\n",
    "#         dout = self.FC2._backward(dout)\n",
    "#         dout = self.ReLU1._backward(dout)\n",
    "#         dout = self.FC1._backward(dout)\n",
    "\n",
    "#     def get_params(self):\n",
    "#         return [self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b]\n",
    "\n",
    "#     def set_params(self, params):\n",
    "#         [self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b] = params\n",
    "\n",
    "\n",
    "# class LeNet5(Net):\n",
    "#     # LeNet5\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.conv1 = Conv(1, 6, 5)\n",
    "#         self.ReLU1 = ReLU()\n",
    "#         self.pool1 = MaxPool(2,2)\n",
    "#         self.conv2 = Conv(6, 16, 5)\n",
    "#         self.ReLU2 = ReLU()\n",
    "#         self.pool2 = MaxPool(2,2)\n",
    "#         self.FC1 = FC(16*4*4, 120)\n",
    "#         self.ReLU3 = ReLU()\n",
    "#         self.FC2 = FC(120, 84)\n",
    "#         self.ReLU4 = ReLU()\n",
    "#         self.FC3 = FC(84, 10)\n",
    "#         self.Softmax = Softmax()\n",
    "\n",
    "#         self.p2_shape = None\n",
    "\n",
    "#     def forward(self, X):\n",
    "#         h1 = self.conv1._forward(X)\n",
    "#         a1 = self.ReLU1._forward(h1)\n",
    "#         p1 = self.pool1._forward(a1)\n",
    "#         h2 = self.conv2._forward(p1)\n",
    "#         a2 = self.ReLU2._forward(h2)\n",
    "#         p2 = self.pool2._forward(a2)\n",
    "#         self.p2_shape = p2.shape\n",
    "#         fl = p2.reshape(X.shape[0],-1) # Flatten\n",
    "#         h3 = self.FC1._forward(fl)\n",
    "#         a3 = self.ReLU3._forward(h3)\n",
    "#         h4 = self.FC2._forward(a3)\n",
    "#         a5 = self.ReLU4._forward(h4)\n",
    "#         h5 = self.FC3._forward(a5)\n",
    "#         a5 = self.Softmax._forward(h5)\n",
    "#         return a5\n",
    "\n",
    "#     def backward(self, dout):\n",
    "#         #dout = self.Softmax._backward(dout)\n",
    "#         dout = self.FC3._backward(dout)\n",
    "#         dout = self.ReLU4._backward(dout)\n",
    "#         dout = self.FC2._backward(dout)\n",
    "#         dout = self.ReLU3._backward(dout)\n",
    "#         dout = self.FC1._backward(dout)\n",
    "#         dout = dout.reshape(self.p2_shape) # reshape\n",
    "#         dout = self.pool2._backward(dout)\n",
    "#         dout = self.ReLU2._backward(dout)\n",
    "#         dout = self.conv2._backward(dout)\n",
    "#         dout = self.pool1._backward(dout)\n",
    "#         dout = self.ReLU1._backward(dout)\n",
    "#         dout = self.conv1._backward(dout)\n",
    "\n",
    "#     def get_params(self):\n",
    "#         return [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b]\n",
    "\n",
    "#     def set_params(self, params):\n",
    "#         [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b] = params\n",
    "\n",
    "# class SGD():\n",
    "#     def __init__(self, params, lr=0.001, reg=0):\n",
    "#         self.parameters = params\n",
    "#         self.lr = lr\n",
    "#         self.reg = reg\n",
    "\n",
    "#     def step(self):\n",
    "#         for param in self.parameters:\n",
    "#             param['val'] -= (self.lr*param['grad'] + self.reg*param['val'])\n",
    "\n",
    "# class SGDMomentum():\n",
    "#     def __init__(self, params, lr=0.001, momentum=0.99, reg=0):\n",
    "#         self.l = len(params)\n",
    "#         self.parameters = params\n",
    "#         self.velocities = []\n",
    "#         for param in self.parameters:\n",
    "#             self.velocities.append(np.zeros(param['val'].shape))\n",
    "#         self.lr = lr\n",
    "#         self.rho = momentum\n",
    "#         self.reg = reg\n",
    "\n",
    "#     def step(self):\n",
    "#         for i in range(self.l):\n",
    "#             self.velocities[i] = self.rho*self.velocities[i] + (1-self.rho)*self.parameters[i]['grad']\n",
    "#             self.parameters[i]['val'] -= (self.lr*self.velocities[i] + self.reg*self.parameters[i]['val'])\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# (1) Prepare Data: Load, Shuffle, Normalization, Batching, Preprocessing\n",
    "# \"\"\"\n",
    "\n",
    "# #mnist.init()\n",
    "# X_train, Y_train, X_test, Y_test = load()\n",
    "# X_train, X_test = X_train/float(255), X_test/float(255)\n",
    "# X_train -= np.mean(X_train)\n",
    "# X_test -= np.mean(X_test)\n",
    "\n",
    "# batch_size = 64\n",
    "# D_in = 784\n",
    "# D_out = 10\n",
    "\n",
    "# print(\"batch_size: \" + str(batch_size) + \", D_in: \" + str(D_in) + \", D_out: \" + str(D_out))\n",
    "\n",
    "# ### TWO LAYER NET FORWARD TEST ###\n",
    "# #H=400\n",
    "# #model = nn.TwoLayerNet(batch_size, D_in, H, D_out)\n",
    "# H1=300\n",
    "# H2=100\n",
    "# model = ThreeLayerNet(batch_size, D_in, H1, H2, D_out)\n",
    "\n",
    "\n",
    "# losses = []\n",
    "# #optim = optimizer.SGD(model.get_params(), lr=0.0001, reg=0)\n",
    "# optim = SGDMomentum(model.get_params(), lr=0.0001, momentum=0.80, reg=0.00003)\n",
    "# criterion = CrossEntropyLoss()\n",
    "\n",
    "# # TRAIN\n",
    "# ITER = 25000\n",
    "# for i in range(ITER):\n",
    "# \t# get batch, make onehot\n",
    "# \tX_batch, Y_batch = get_batch(X_train, Y_train, batch_size)\n",
    "# \tY_batch = MakeOneHot(Y_batch, D_out)\n",
    "\n",
    "# \t# forward, loss, backward, step\n",
    "# \tY_pred = model.forward(X_batch)\n",
    "# \tloss, dout = criterion.get(Y_pred, Y_batch)\n",
    "# \tmodel.backward(dout)\n",
    "# \toptim.step()\n",
    "\n",
    "# \tif i % 100 == 0:\n",
    "# \t\tprint(\"%s%% iter: %s, loss: %s\" % (100*i/ITER,i, loss))\n",
    "# \t\tlosses.append(loss)\n",
    "\n",
    "\n",
    "# # save params\n",
    "# weights = model.get_params()\n",
    "# with open(\"weights.pkl\",\"wb\") as f:\n",
    "# \tpickle.dump(weights, f)\n",
    "\n",
    "# draw_losses(losses)\n",
    "\n",
    "\n",
    "\n",
    "# # TRAIN SET ACC\n",
    "# Y_pred = model.forward(X_train)\n",
    "# result = np.argmax(Y_pred, axis=1) - Y_train\n",
    "# result = list(result)\n",
    "# print(\"TRAIN--> Correct: \" + str(result.count(0)) + \" out of \" + str(X_train.shape[0]) + \", acc=\" + str(result.count(0)/X_train.shape[0]))\n",
    "\n",
    "# # TEST SET ACC\n",
    "# Y_pred = model.forward(X_test)\n",
    "# result = np.argmax(Y_pred, axis=1) - Y_test\n",
    "# result = list(result)\n",
    "# print(\"TEST--> Correct: \" + str(result.count(0)) + \" out of \" + str(X_test.shape[0]) + \", acc=\" + str(result.count(0)/X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
