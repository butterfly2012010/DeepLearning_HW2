{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "#################################################\n",
    "import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "# import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"# cpus: \", os.cpu_count())\n",
    "NUM_PROCESSES = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [00:52<00:00, 1208.34it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 469628.46it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 417297.55it/s]\n",
      "100%|██████████| 63325/63325 [00:53<00:00, 1179.90it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 1738.43it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 1711.22it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./train.txt\") as f:\n",
    "    train_file_list = f.readlines()\n",
    "with open(\"./val.txt\") as f:\n",
    "    val_file_list = f.readlines()\n",
    "with open(\"./test.txt\") as f:\n",
    "    test_file_list = f.readlines()\n",
    "\n",
    "train_file_list = [x.strip().split(sep=\" \") for x in train_file_list]\n",
    "val_file_list = [x.strip().split(sep=\" \") for x in val_file_list]\n",
    "test_file_list = [x.strip().split(sep=\" \") for x in test_file_list]\n",
    "\n",
    "train_label = [int(x[1]) for x in train_file_list]\n",
    "val_label = [int(x[1]) for x in val_file_list]\n",
    "test_label = [int(x[1]) for x in test_file_list]\n",
    "\n",
    "train_file_list = [x[0] for x in train_file_list]\n",
    "val_file_list = [x[0] for x in val_file_list]\n",
    "test_file_list = [x[0] for x in test_file_list]\n",
    "\n",
    "# print(\"# cpus: \", os.cpu_count())\n",
    "NUM_PROCESSES = 8\n",
    "\n",
    "def ReadImage(filePath):\n",
    "    image = cv2.imread(filePath, cv2.IMREAD_COLOR)\n",
    "    # image = cv2.imread(filePath, cv2.IMREAD_GRAYSCALE)\n",
    "    # image = cv2.resize(image, (256, 256))\n",
    "    return image\n",
    "\n",
    "with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "    train_imgs = pool.map(ReadImage, tqdm(train_file_list))\n",
    "    val_imgs = pool.map(ReadImage, tqdm(val_file_list))\n",
    "    test_imgs = pool.map(ReadImage, tqdm(test_file_list))\n",
    "\n",
    "# resize the images to 256x256\n",
    "def ResizeImage(image):\n",
    "    # resized_img = cv2.resize(image, (256, 256))\n",
    "    resized_img = cv2.resize(image, (32, 32))\n",
    "    return resized_img\n",
    "\n",
    "with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "    resized_train_imgs = pool.map(ResizeImage, tqdm(train_imgs))\n",
    "    resized_val_imgs = pool.map(ResizeImage, tqdm(val_imgs))\n",
    "    resized_test_imgs = pool.map(ResizeImage, tqdm(test_imgs))\n",
    "\n",
    "##########################################################################################################\n",
    "# def FlattenImages(image: np.ndarray) -> np.ndarray:\n",
    "#     return image.flatten()\n",
    "\n",
    "# with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "#     flatten_resized_train_imgs = np.array(pool.map(FlattenImages, tqdm(resized_train_imgs)))\n",
    "#     flatten_resized_val_imgs = np.array(pool.map(FlattenImages, tqdm(resized_val_imgs)))\n",
    "#     flatten_resized_test_imgs = np.array(pool.map(FlattenImages, tqdm(resized_test_imgs)))\n",
    "\n",
    "\n",
    "# # Ref.: https://github.com/Ixiaohuihuihui/Extract-color-histogram-feature/blob/master/rgb_feature.py\n",
    "# # extract rgb features\n",
    "# def ExtractColorHistFeatures(image):\n",
    "#     features = []\n",
    "#     for channel in range(3):\n",
    "#         hist = cv2.calcHist(images=[image], channels=[channel], mask=None, histSize=[64], ranges=[0,256])\n",
    "#         hist = cv2.normalize(hist, hist)\n",
    "#         # features.extend(hist)\n",
    "#         features.append(hist)\n",
    "#     return features\n",
    "\n",
    "# with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "#     ### tqdm returns an iterator\n",
    "#     # train_features = pool.map(ExtractFeatures, tqdm(resized_train_imgs))\n",
    "#     # val_features = pool.map(ExtractFeatures, tqdm(resized_val_imgs))\n",
    "#     # test_features = pool.map(ExtractFeatures, tqdm(resized_test_imgs))\n",
    "#     train_features = list(tqdm(pool.imap(ExtractColorHistFeatures, resized_train_imgs), total=len(resized_train_imgs)))\n",
    "#     val_features = list(tqdm(pool.imap(ExtractColorHistFeatures, resized_val_imgs), total=len(resized_val_imgs)))\n",
    "#     test_features = list(tqdm(pool.imap(ExtractColorHistFeatures, resized_test_imgs), total=len(resized_test_imgs)))\n",
    "\n",
    "\n",
    "# # flatten and reshape the features into (n_samples, n_features)\n",
    "# train_features = np.array(train_features)\n",
    "# val_features = np.array(val_features)\n",
    "# test_features = np.array(test_features)\n",
    "\n",
    "# def FlattenFeatures(feature):\n",
    "#     return feature.flatten()\n",
    "\n",
    "# with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "#     train_features = np.array(pool.map(FlattenFeatures, tqdm(train_features)))\n",
    "#     val_features = np.array(pool.map(FlattenFeatures, tqdm(val_features)))\n",
    "#     test_features = np.array(pool.map(FlattenFeatures, tqdm(test_features)))\n",
    "\n",
    "# # flatten and reshape the features into (n_samples, n_features)\n",
    "# resized_train_imgs = np.array(resized_train_imgs)\n",
    "# resized_val_imgs = np.array(resized_val_imgs)\n",
    "# resized_test_imgs = np.array(resized_test_imgs)\n",
    "\n",
    "# def FlattenImages(image):\n",
    "#     return image.flatten()\n",
    "\n",
    "# with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "#     resized_train_imgs = np.array(pool.map(FlattenImages, tqdm(resized_train_imgs)))\n",
    "#     resized_val_imgs = np.array(pool.map(FlattenImages, tqdm(resized_val_imgs)))\n",
    "#     resized_test_imgs = np.array(pool.map(FlattenImages, tqdm(resized_test_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=\"./data/resized_train_imgs.npy\", arr=resized_train_imgs)\n",
    "np.save(file=\"./data/resized_val_imgs.npy\", arr=resized_val_imgs)\n",
    "np.save(file=\"./data/resized_test_imgs.npy\", arr=resized_test_imgs)\n",
    "np.save(file=\"./data/train_label\", arr=train_label)\n",
    "np.save(file=\"./data/val_label\", arr=val_label)\n",
    "np.save(file=\"./data/test_label\", arr=test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_train_imgs = np.load(file=\"./data/resized_train_imgs.npy\")\n",
    "resized_val_imgs = np.load(file=\"./data/resized_val_imgs.npy\")\n",
    "resized_test_imgs = np.load(file=\"./data/resized_test_imgs.npy\")\n",
    "train_label = np.load(file=\"./data/train_label.npy\")\n",
    "val_label = np.load(file=\"./data/val_label.npy\")\n",
    "test_label = np.load(file=\"./data/test_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [00:03<00:00, 16971.22it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 25501.08it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 26289.62it/s]\n"
     ]
    }
   ],
   "source": [
    "def MoveColorChannel(image: np.ndarray) -> np.ndarray:\n",
    "    return np.moveaxis(image, source=2, destination=0)  # reshape (H, W, C) to (C, H, W)\n",
    "\n",
    "with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "    resized_train_imgs = pool.map(MoveColorChannel, tqdm(resized_train_imgs))\n",
    "    resized_val_imgs = pool.map(MoveColorChannel, tqdm(resized_val_imgs))\n",
    "    resized_test_imgs = pool.map(MoveColorChannel, tqdm(resized_test_imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shuffle\n",
    "# def shuffle(imgs: list, label: list) -> list:\n",
    "#     random.seed(42)\n",
    "#     idx = np.arange(len(imgs))\n",
    "#     random.shuffle(idx)\n",
    "#     imgs = [imgs[i] for i in idx]\n",
    "#     label = [label[i] for i in idx]\n",
    "#     return imgs, label\n",
    "\n",
    "# resized_train_imgs, train_label = shuffle(resized_train_imgs, train_label)\n",
    "# resized_val_imgs, val_label = shuffle(resized_val_imgs, val_label)\n",
    "# resized_test_imgs, test_label = shuffle(resized_test_imgs, test_label)\n",
    "\n",
    "# convert list to numpy.ndarray\n",
    "resized_train_imgs = np.array(resized_train_imgs)\n",
    "resized_val_imgs = np.array(resized_val_imgs)\n",
    "resized_test_imgs = np.array(resized_test_imgs)\n",
    "# list to numpy.ndarray\n",
    "train_label = np.array(train_label)\n",
    "val_label = np.array(val_label)\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63325, 3, 64, 64)\n",
      "(450, 3, 64, 64)\n",
      "(450, 3, 64, 64)\n",
      "\n",
      "(63325,)\n",
      "(63325,)\n",
      "(63325,)\n"
     ]
    }
   ],
   "source": [
    "# check the shape\n",
    "print(resized_train_imgs.shape)\n",
    "print(resized_val_imgs.shape)\n",
    "print(resized_test_imgs.shape)\n",
    "print()\n",
    "print(train_label.shape)\n",
    "print(val_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeOneHot(Y, D_out):\n",
    "    N = Y.shape[0]\n",
    "    Z = np.zeros((N, D_out))\n",
    "    Z[np.arange(N), Y] = 1\n",
    "    return Z\n",
    "\n",
    "def draw_losses(losses):\n",
    "    t = np.arange(len(losses))\n",
    "    plt.plot(t, losses)\n",
    "    plt.show()\n",
    "\n",
    "def get_batch(X, Y, batch_size):\n",
    "    N = len(X)\n",
    "    i = random.randint(1, N-batch_size)\n",
    "    return X[i:i+batch_size], Y[i:i+batch_size]\n",
    "\n",
    "class FC():\n",
    "    \"\"\"\n",
    "    Fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self, D_in, D_out):\n",
    "        #print(\"Build FC\")\n",
    "        self.cache = None\n",
    "        #self.W = {'val': np.random.randn(D_in, D_out), 'grad': 0}\n",
    "        self.W = {'val': np.random.normal(0.0, np.sqrt(2/D_in), (D_in,D_out)), 'grad': 0}\n",
    "        self.b = {'val': np.random.randn(D_out), 'grad': 0}\n",
    "\n",
    "    def _forward(self, X):\n",
    "        #print(\"FC: _forward\")\n",
    "        out = np.dot(X, self.W['val']) + self.b['val']\n",
    "        self.cache = X\n",
    "        return out\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        #print(\"FC: _backward\")\n",
    "        X = self.cache\n",
    "        dX = np.dot(dout, self.W['val'].T).reshape(X.shape)\n",
    "        self.W['grad'] = np.dot(X.reshape(X.shape[0], np.prod(X.shape[1:])).T, dout)\n",
    "        self.b['grad'] = np.sum(dout, axis=0)\n",
    "        #self._update_params()\n",
    "        return dX\n",
    "\n",
    "    def _update_params(self, lr=0.001):\n",
    "        # Update the parameters\n",
    "        self.W['val'] -= lr*self.W['grad']\n",
    "        self.b['val'] -= lr*self.b['grad']\n",
    "\n",
    "class ReLU():\n",
    "    \"\"\"\n",
    "    ReLU activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        #print(\"Build ReLU\")\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        #print(\"ReLU: _forward\")\n",
    "        out = np.maximum(0, X)\n",
    "        self.cache = X\n",
    "        return out\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        #print(\"ReLU: _backward\")\n",
    "        X = self.cache\n",
    "        dX = np.array(dout, copy=True)\n",
    "        dX[X <= 0] = 0\n",
    "        return dX\n",
    "\n",
    "class Sigmoid():\n",
    "    \"\"\"\n",
    "    Sigmoid activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        self.cache = X\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X = self.cache\n",
    "        X = self._forward(X)  # 與原作者不同，新增這行\n",
    "        dX = dout*X*(1-X)\n",
    "        return dX\n",
    "\n",
    "class tanh():\n",
    "    \"\"\"\n",
    "    tanh activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.cache = X\n",
    "\n",
    "    def _forward(self, X):\n",
    "        self.cache = X\n",
    "        return np.tanh(X)\n",
    "\n",
    "    def _backward(self, X):\n",
    "        X = self.cache\n",
    "        dX = dout*(1 - np.tanh(X)**2)\n",
    "        return dX\n",
    "\n",
    "class Softmax():\n",
    "    \"\"\"\n",
    "    Softmax activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        #print(\"Build Softmax\")\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        #print(\"Softmax: _forward\")\n",
    "        maxes = np.amax(X, axis=1)\n",
    "        maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "        Y = np.exp(X - maxes)\n",
    "        Z = Y / np.sum(Y, axis=1).reshape(Y.shape[0], 1)\n",
    "        self.cache = (X, Y, Z)\n",
    "        return Z # distribution\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X, Y, Z = self.cache\n",
    "        dZ = np.zeros(X.shape)\n",
    "        dY = np.zeros(X.shape)\n",
    "        dX = np.zeros(X.shape)\n",
    "        N = X.shape[0]\n",
    "        for n in range(N):\n",
    "            i = np.argmax(Z[n])\n",
    "            dZ[n,:] = np.diag(Z[n]) - np.outer(Z[n],Z[n])\n",
    "            M = np.zeros((N,N))\n",
    "            M[:,i] = 1\n",
    "            dY[n,:] = np.eye(N) - M\n",
    "        dX = np.dot(dout,dZ)\n",
    "        dX = np.dot(dX,dY)\n",
    "        return dX\n",
    "\n",
    "\n",
    "class Dropout():\n",
    "    \"\"\"\n",
    "    Dropout layer\n",
    "    \"\"\"\n",
    "    def __init__(self, p=1):\n",
    "        self.cache = None\n",
    "        self.p = p\n",
    "\n",
    "    def _forward(self, X):\n",
    "        M = (np.random.rand(*X.shape) < self.p) / self.p\n",
    "        self.cache = X, M\n",
    "        return X*M\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X, M = self.cache\n",
    "        dX = dout*M/self.p\n",
    "        return dX\n",
    "\n",
    "class Conv():\n",
    "    \"\"\"\n",
    "    Conv layer\n",
    "    \"\"\"\n",
    "    def __init__(self, Cin, Cout, F, stride=1, padding=0, bias=True):\n",
    "        self.Cin = Cin\n",
    "        self.Cout = Cout\n",
    "        self.F = F\n",
    "        self.S = stride\n",
    "        #self.W = {'val': np.random.randn(Cout, Cin, F, F), 'grad': 0}\n",
    "        self.W = {'val': np.random.normal(0.0,np.sqrt(2/Cin),(Cout,Cin,F,F)), 'grad': 0} # Xavier Initialization\n",
    "        self.b = {'val': np.random.randn(Cout), 'grad': 0}\n",
    "        self.cache = None\n",
    "        self.pad = padding\n",
    "\n",
    "    def _forward(self, X):\n",
    "        X = np.pad(X, ((0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)), 'constant')\n",
    "        (N, Cin, H, W) = X.shape\n",
    "        H_ = H - self.F + 1\n",
    "        W_ = W - self.F + 1\n",
    "        Y = np.zeros((N, self.Cout, H_, W_))\n",
    "\n",
    "        for n in range(N):\n",
    "            for c in range(self.Cout):\n",
    "                for h in range(H_):\n",
    "                    for w in range(W_):\n",
    "                        Y[n, c, h, w] = np.sum(X[n, :, h:h+self.F, w:w+self.F] * self.W['val'][c, :, :, :]) + self.b['val'][c]\n",
    "\n",
    "        self.cache = X\n",
    "        return Y\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        # dout (N,Cout,H_,W_)\n",
    "        # W (Cout, Cin, F, F)\n",
    "        X = self.cache\n",
    "        (N, Cin, H, W) = X.shape\n",
    "        H_ = H - self.F + 1\n",
    "        W_ = W - self.F + 1\n",
    "        W_rot = np.rot90(np.rot90(self.W['val']))\n",
    "\n",
    "        dX = np.zeros(X.shape)\n",
    "        dW = np.zeros(self.W['val'].shape)\n",
    "        db = np.zeros(self.b['val'].shape)\n",
    "\n",
    "        # dW\n",
    "        for co in range(self.Cout):\n",
    "            for ci in range(Cin):\n",
    "                for h in range(self.F):\n",
    "                    for w in range(self.F):\n",
    "                        dW[co, ci, h, w] = np.sum(X[:,ci,h:h+H_,w:w+W_] * dout[:,co,:,:])\n",
    "\n",
    "        # db\n",
    "        for co in range(self.Cout):\n",
    "            db[co] = np.sum(dout[:,co,:,:])\n",
    "\n",
    "        dout_pad = np.pad(dout, ((0,0),(0,0),(self.F,self.F),(self.F,self.F)), 'constant')\n",
    "        #print(\"dout_pad.shape: \" + str(dout_pad.shape))\n",
    "        # dX\n",
    "        for n in range(N):\n",
    "            for ci in range(Cin):\n",
    "                for h in range(H):\n",
    "                    for w in range(W):\n",
    "                        #print(\"self.F.shape: %s\", self.F)\n",
    "                        #print(\"%s, W_rot[:,ci,:,:].shape: %s, dout_pad[n,:,h:h+self.F,w:w+self.F].shape: %s\" % ((n,ci,h,w),W_rot[:,ci,:,:].shape, dout_pad[n,:,h:h+self.F,w:w+self.F].shape))\n",
    "                        dX[n, ci, h, w] = np.sum(W_rot[:,ci,:,:] * dout_pad[n, :, h:h+self.F,w:w+self.F])\n",
    "\n",
    "        return dX\n",
    "\n",
    "class MaxPool():\n",
    "    def __init__(self, F, stride):\n",
    "        self.F = F\n",
    "        self.S = stride\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        # X: (N, Cin, H, W): maxpool along 3rd, 4th dim\n",
    "        (N,Cin,H,W) = X.shape\n",
    "        F = self.F\n",
    "        W_ = int(float(W)/F)\n",
    "        H_ = int(float(H)/F)\n",
    "        Y = np.zeros((N,Cin,W_,H_))\n",
    "        M = np.zeros(X.shape) # mask\n",
    "        for n in range(N):\n",
    "            for cin in range(Cin):\n",
    "                for w_ in range(W_):\n",
    "                    for h_ in range(H_):\n",
    "                        Y[n,cin,w_,h_] = np.max(X[n,cin,F*w_:F*(w_+1),F*h_:F*(h_+1)])\n",
    "                        i,j = np.unravel_index(X[n,cin,F*w_:F*(w_+1),F*h_:F*(h_+1)].argmax(), (F,F))\n",
    "                        M[n,cin,F*w_+i,F*h_+j] = 1\n",
    "        self.cache = M\n",
    "        return Y\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        M = self.cache\n",
    "        (N,Cin,H,W) = M.shape\n",
    "        dout = np.array(dout)\n",
    "        #print(\"dout.shape: %s, M.shape: %s\" % (dout.shape, M.shape))\n",
    "        dX = np.zeros(M.shape)\n",
    "        for n in range(N):\n",
    "            for c in range(Cin):\n",
    "                #print(\"(n,c): (%s,%s)\" % (n,c))\n",
    "                dX[n,c,:,:] = dout[n,c,:,:].repeat(2, axis=0).repeat(2, axis=1)\n",
    "        return dX*M\n",
    "\n",
    "def NLLLoss(Y_pred, Y_true):\n",
    "    \"\"\"\n",
    "    Negative log likelihood loss\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    N = Y_pred.shape[0]\n",
    "    M = np.sum(Y_pred*Y_true, axis=1)\n",
    "    for e in M:\n",
    "        #print(e)\n",
    "        if e == 0:\n",
    "            loss += 500\n",
    "        else:\n",
    "            loss += -np.log(e)\n",
    "    return loss/N\n",
    "\n",
    "class CrossEntropyLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get(self, Y_pred, Y_true):\n",
    "        N = Y_pred.shape[0]\n",
    "        softmax = Softmax()\n",
    "        prob = softmax._forward(Y_pred)\n",
    "        loss = NLLLoss(prob, Y_true)\n",
    "        Y_serial = np.argmax(Y_true, axis=1)\n",
    "        dout = prob.copy()\n",
    "        dout[np.arange(N), Y_serial] -= 1\n",
    "        return loss, dout\n",
    "\n",
    "class SoftmaxLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get(self, Y_pred, Y_true):\n",
    "        N = Y_pred.shape[0]\n",
    "        loss = NLLLoss(Y_pred, Y_true)\n",
    "        Y_serial = np.argmax(Y_true, axis=1)\n",
    "        dout = Y_pred.copy()\n",
    "        dout[np.arange(N), Y_serial] -= 1\n",
    "        return loss, dout\n",
    "\n",
    "class Net(metaclass=ABCMeta):\n",
    "    # Neural network super class\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, X):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward(self, dout):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_params(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_params(self, params):\n",
    "        pass\n",
    "\n",
    "\n",
    "class LeNet5(Net):\n",
    "    # LeNet5\n",
    "\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv(3, 6, 5)\n",
    "        self.ReLU1 = ReLU()\n",
    "        self.pool1 = MaxPool(2,2)\n",
    "        self.conv2 = Conv(6, 16, 5)\n",
    "        self.ReLU2 = ReLU()\n",
    "        self.pool2 = MaxPool(2,2)\n",
    "        self.FC1 = FC(16*13*13, 120)\n",
    "        self.ReLU3 = ReLU()\n",
    "        self.FC2 = FC(120, 84)\n",
    "        self.ReLU4 = ReLU()\n",
    "        self.FC3 = FC(84, 50)\n",
    "        self.Softmax = Softmax()\n",
    "\n",
    "        self.p2_shape = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        h1 = self.conv1._forward(X)\n",
    "        a1 = self.ReLU1._forward(h1)\n",
    "        p1 = self.pool1._forward(a1)\n",
    "        h2 = self.conv2._forward(p1)\n",
    "        a2 = self.ReLU2._forward(h2)\n",
    "        p2 = self.pool2._forward(a2)\n",
    "        self.p2_shape = p2.shape\n",
    "        fl = p2.reshape(X.shape[0],-1) # Flatten\n",
    "        h3 = self.FC1._forward(fl)\n",
    "        a3 = self.ReLU3._forward(h3)\n",
    "        h4 = self.FC2._forward(a3)\n",
    "        a5 = self.ReLU4._forward(h4)\n",
    "        h5 = self.FC3._forward(a5)\n",
    "        a5 = self.Softmax._forward(h5)\n",
    "        return a5\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # dout = self.Softmax._backward(dout)\n",
    "        dout = self.FC3._backward(dout)\n",
    "        dout = self.ReLU4._backward(dout)\n",
    "        dout = self.FC2._backward(dout)\n",
    "        dout = self.ReLU3._backward(dout)\n",
    "        dout = self.FC1._backward(dout)\n",
    "        dout = dout.reshape(self.p2_shape) # reshape\n",
    "        dout = self.pool2._backward(dout)\n",
    "        dout = self.ReLU2._backward(dout)\n",
    "        dout = self.conv2._backward(dout)\n",
    "        dout = self.pool1._backward(dout)\n",
    "        dout = self.ReLU1._backward(dout)\n",
    "        dout = self.conv1._backward(dout)\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b] = params\n",
    "\n",
    "class SGD():\n",
    "    def __init__(self, params, lr=0.001, reg=0):\n",
    "        self.parameters = params\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.parameters:\n",
    "            param['val'] -= (self.lr*param['grad'] + self.reg*param['val'])\n",
    "\n",
    "class SGDMomentum():\n",
    "    def __init__(self, params, lr=0.001, momentum=0.99, reg=0):\n",
    "        self.l = len(params)\n",
    "        self.parameters = params\n",
    "        self.velocities = []\n",
    "        for param in self.parameters:\n",
    "            self.velocities.append(np.zeros(param['val'].shape))\n",
    "        self.lr = lr\n",
    "        self.rho = momentum\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for i in range(self.l):\n",
    "            self.velocities[i] = self.rho*self.velocities[i] + (1-self.rho)*self.parameters[i]['grad']\n",
    "            self.parameters[i]['val'] -= (self.lr*self.velocities[i] + self.reg*self.parameters[i]['val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data, labels, batch_size=64, shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_samples = data.shape[0]\n",
    "        self.num_batches = int(np.ceil(self.num_samples / self.batch_size))\n",
    "        self.indices = np.arange(self.num_samples)\n",
    "        self.current_batch = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current_batch >= self.num_batches:\n",
    "            self.current_batch = 0\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.indices)\n",
    "            raise StopIteration\n",
    "            \n",
    "        batch_indices = self.indices[self.current_batch*self.batch_size : (self.current_batch+1)*self.batch_size]\n",
    "        batch_data = self.data[batch_indices]\n",
    "        batch_labels = self.labels[batch_indices]\n",
    "        \n",
    "        self.current_batch += 1\n",
    "        \n",
    "        return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 64, D_out: 50\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "(1) Prepare Data: Load, Shuffle, Normalization, Batching, Preprocessing\n",
    "\"\"\"\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = resized_train_imgs, train_label, resized_test_imgs, test_label\n",
    "X_train, X_test = X_train/float(255), X_test/float(255)\n",
    "X_train -= np.mean(X_train)\n",
    "X_test -= np.mean(X_test)\n",
    "\n",
    "batch_size = 64\n",
    "# D_in = 784\n",
    "D_out = 50\n",
    "\n",
    "# print(\"batch_size: \" + str(batch_size) + \", D_in: \" + str(D_in) + \", D_out: \" + str(D_out))\n",
    "print(\"batch_size: \" + str(batch_size) + \", D_out: \" + str(D_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 779/990 [9:44:23<2:38:17, 45.01s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16516/3306230002.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# loss, dout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY_batch\u001b[0m  \u001b[0;31m# pred - label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16516/306239284.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16516/306239284.py\u001b[0m in \u001b[0;36m_backward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m    216\u001b[0m                         \u001b[0;31m#print(\"self.F.shape: %s\", self.F)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                         \u001b[0;31m#print(\"%s, W_rot[:,ci,:,:].shape: %s, dout_pad[n,:,h:h+self.F,w:w+self.F].shape: %s\" % ((n,ci,h,w),W_rot[:,ci,:,:].shape, dout_pad[n,:,h:h+self.F,w:w+self.F].shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                         \u001b[0mdX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_rot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdout_pad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2123\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sum_dispatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2124\u001b[0m def sum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n\u001b[1;32m   2125\u001b[0m         initial=np._NoValue, where=np._NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Lenet Forward Test ###\n",
    "model = LeNet5()\n",
    "dataloader = DataLoader(data=resized_train_imgs,\n",
    "                        labels=train_label,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True)\n",
    "\n",
    "losses = []\n",
    "optim = SGDMomentum(params=model.get_params(), lr=1e-3, momentum=0.99, reg=0)\n",
    "# optim = SGD(params=model.get_params(), lr=1e-3, reg=0)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Train\n",
    "EPOCHS = 5\n",
    "for i in range(EPOCHS):\n",
    "    losses_epoch = 0\n",
    "    print(f\"epoch: {i+1}\")\n",
    "    with tqdm(total=dataloader.num_batches) as pbar:\n",
    "        for X_batch, Y_batch in dataloader:\n",
    "            # get batch, make onehot\n",
    "            # X_batch, Y_batch = get_batch(X_train, Y_train, batch_size)\n",
    "            Y_batch = MakeOneHot(Y_batch, D_out)\n",
    "\n",
    "            # forward, loss, backward, step\n",
    "            Y_pred = model.forward(X_batch)\n",
    "            loss, _ = criterion.get(Y_pred, Y_batch)  # loss, dout\n",
    "            dout = Y_pred - Y_batch  # pred - label\n",
    "            model.backward(dout)\n",
    "            optim.step()\n",
    "\n",
    "            losses_epoch += loss\n",
    "            pbar.update(1)\n",
    "\n",
    "        losses_epoch /= dataloader.num_batches\n",
    "            \n",
    "    if i % 1 == 0:\n",
    "        print(\"%s%% epoch: %s, train loss: %s\" % (round(100*(i+1)/EPOCHS, 4), i+1, round(losses_epoch, 4)))\n",
    "        losses.append(losses_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save params\n",
    "weights = model.get_params()\n",
    "with open(\"weights.pkl\",\"wb\") as f:\n",
    "\tpickle.dump(weights, f)\n",
    "\n",
    "draw_losses(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SET ACC\n",
    "Y_pred = model.forward(X_train)\n",
    "result = np.argmax(Y_pred, axis=1) - Y_train\n",
    "result = list(result)\n",
    "print(\"TRAIN--> Correct: \" + str(result.count(0)) + \" out of \" + str(X_train.shape[0]) + \", acc=\" + str(result.count(0)/X_train.shape[0]))\n",
    "\n",
    "# TEST SET ACC\n",
    "Y_pred = model.forward(X_test)\n",
    "result = np.argmax(Y_pred, axis=1) - Y_test\n",
    "result = list(result)\n",
    "print(\"TEST--> Correct: \" + str(result.count(0)) + \" out of \" + str(X_test.shape[0]) + \", acc=\" + str(result.count(0)/X_test.shape[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
